{
    "primary_language": "C++",
    "language_guidelines": "# General Guidelines : \n**General Guidelines for C/C++ Projects**\n\n1. **Read the README**  \n   Start by reading the project's README file on GitHub. It contains important instructions for installation, usage, and project-specific details.  \n\n2. **Check Dependencies**  \n   Look for dependencies listed in the README or package management files like `CMakeLists.txt` (for CMake), `Makefile` (for Make), or `vcpkg.json` (for vcpkg). Ensure the required compiler and libraries are installed.  \n\n3. **Build Tool**  \n   Identify the build tool the project is using: Make, CMake, or another. This information should be available in the README or through project configuration files (e.g., `Makefile` for Make, `CMakeLists.txt` for CMake).  \n\n4. **Build the Project**  \n   Depending on the build tool, use the appropriate commands to build the project:  \n\n   - For Make:  \n     ```  \n     make  \n     ```  \n   - For CMake:  \n     ```  \n     mkdir build  \n     cd build  \n     cmake ..  \n     make  \n     ```  \n\n5. **Configuration**  \n   Check if the project requires configuration files (e.g., `.conf` files, `config.h` headers) to be set up. This may involve providing paths to dependencies or setting compilation flags.  \n\n6. **Run Tests (if available)**  \n   If the project provides tests, it's a good idea to run them to ensure everything is working correctly. Common testing frameworks for C/C++ include Google Test (gtest), Catch2, and Boost.Test.  \n   - For Google Test:  \n     ```  \n     ./path/to/test_executable  \n     ```  \n   - For Catch2:  \n     ```  \n     ./path/to/test_executable  \n     ```  \n\n7. **Run the Project**  \n   Follow the instructions in the README to run the project. This could involve running a specific executable, starting a server, or executing a specific command.  \n\n8. **Troubleshooting**  \n   If you encounter issues during installation or while running the project, refer to the project's issue tracker on GitHub or search for similar issues.  \n\n9. **Documentation**  \n   Review additional documentation such as Doxygen files, API documentation, or inline comments in the code. Understanding the documentation provides better insights into the project\u2019s structure and usage.  ",
    "workflow_guidelines": "\nThe following workflow files might contain information on how to set up the project and run test cases.  This might be useful later on when building/installing and testing the project:\n\nfile: llvm_builder.yml\nContent:\nname: Halide LLVM Builder\non:\n  # Run every day at 1AM Pacific; GitHub uses UTC for cron, so that's 9AM\n  schedule:\n    - cron:  '0 9 * * *'\n  #\n  # This is a webhook to allow forcing rebuilds. To use, do this:\n  #\n  #    echo curl -X POST https://api.github.com/repos/halide/Halide/dispatches \\\n  #       -H \"Accept: application/vnd.github.everest-preview+json\" \\\n  #       -H \"Authorization: token ${AUTH_TOKEN}\" \\\n  #       --data \"{'event_type': 'halide_llvm_builder_force_rebuild:${GLOB}'}\"\n  #\n  #    ...where GLOB is a glob pattern for the LLVM versions to rebuild\n  #    (e.g., * = all, *osx* is all osx builds, etc) matching the job name\n  #\n  #    ...and AUTH_TOKEN is a personal access token for your account\n  #    (see https://help.github.com/en/github/authenticating-to-github/creating-a-personal-access-token-for-the-command-line)\n  #\n  repository_dispatch:\n\njobs:\n  build_llvm:\n    name: llvm-${{matrix.llvm_version}}-${{matrix.target_arch}}-${{matrix.target_bits}}-${{matrix.target_os}}\n    runs-on: ${{matrix.host_os}}\n    env:\n      CC: ${{matrix.cc}}\n      CXX: ${{matrix.cxx}}\n      LD: ${{matrix.ld}}\n\n    strategy:\n      fail-fast: false  # Keep running even if one job fails\n      matrix:\n        target_arch: [x86, arm]\n        target_bits: [32, 64]\n        target_os: [windows, linux, osx]\n        llvm_version: [10, 11, 12]\n        include:\n          - llvm_version: 10\n            llvm_branch: release/10.x\n          - llvm_version: 11\n            llvm_branch: release/11.x\n          - llvm_version: 12\n            llvm_branch: master\n\n          # map things to the necessary host cross-compiler host\n          - target_os: osx\n            host_os: macos-10.15\n            cc: clang\n            cxx: clang++\n            ld: ld\n\n          - target_os: linux\n            host_os: ubuntu-18.04\n            # GHA has clang 6, 8, and 9 and GCC 7.4, 8.3, 9.2 preinstalled.\n            # We will explicitly choose gcc 7.x (even though the default is gcc 7.4)\n            # To ensure we match gcc versions with the arm crosscompiler.\n            cc: gcc-7\n            cxx: g++-7\n            ld: ld\n\n          - target_os: windows\n            host_os: windows-2019\n            cc: cl.exe\n            cxx: cl.exe\n            ld: ld.exe\n\n        exclude:\n          # We don't support 32-bit macos builds\n          - target_os: osx\n            target_bits: 32\n          # arm is only supported for target_os == linux, but GHA doesn't\n          # allow adding new entries to the matrix (only excluding them)\n          - target_os: windows\n            target_arch: arm\n          - target_os: osx\n            target_arch: arm\n\n    steps:\n    - name: Configure Ubuntu Host\n      if: startsWith(matrix.host_os, 'ubuntu')\n      shell: bash\n      run: |\n        sudo apt-get update\n        sudo apt-get install ninja-build\n\n        if [[ ${{matrix.target_arch}} == x86 && \\\n              ${{matrix.target_os}} == linux && \\\n              ${{matrix.target_bits}} == 32 ]]; then\n          sudo apt-get install ${{matrix.cc}}-multilib ${{matrix.cxx}}-multilib\n        fi\n\n        if [[ ${{matrix.target_arch}} == arm ]]; then\n          if [[ ${{matrix.target_bits}} == 32 ]]; then\n            sudo apt-get install ${{matrix.cc}}-arm-linux-gnueabihf ${{matrix.cxx}}-arm-linux-gnueabihf\n          else\n            sudo apt-get install ${{matrix.cc}}-aarch64-linux-gnu ${{matrix.cxx}}-aarch64-linux-gnu\n          fi\n        fi\n\n    - name: Configure MacOS Host\n      if: startsWith(matrix.host_os, 'macos')\n      shell: bash\n      run: |\n        brew install ninja\n\n    - name: Configure Windows Host\n      if: startsWith(matrix.host_os, 'windows')\n      run: |\n        # We don't use ninja on Windows (yet)\n        # choco install ninja\n\n    - name: Build llvm-${{matrix.llvm_version}}-${{matrix.target_arch}}-${{matrix.target_bits}}-${{matrix.target_os}}\n      shell: bash\n      run: |\n        set -eu\n\n        # Demangle Windows names, to simplify CMake stuff later\n        _ROOT=${GITHUB_WORKSPACE//\\\\//}\n\n        LLVM_ID=\"llvm-${{matrix.llvm_version}}-${{matrix.target_arch}}-${{matrix.target_bits}}-${{matrix.target_os}}\"\n        LLVM_SOURCE_DIR=\"${_ROOT}/${LLVM_ID}-source\"\n        LLVM_BUILD_DIR=\"${_ROOT}/${LLVM_ID}-build\"\n        LLVM_INSTALL_DIR=\"${_ROOT}/${LLVM_ID}-install\"\n        LLVM_INSTALL_TGZ=\"${_ROOT}/${LLVM_ID}.tgz\"\n        LLVM_INSTALL_URL=\"https://buildbot.halide-lang.org/llvm/${LLVM_ID}.tgz\"\n        LLVM_COMMIT_HASH_FILE=\".halide_builder_llvm_commit\"\n\n        TAR_CMD=\"tar\"\n        if [[ ${{matrix.host_os}} == windows* ]]; then\n          # Must use --force-local to avoid tar misinterpreting the : in\n          # a Windows pathname as a hostname.\n          TAR_CMD=\"tar --force-local\"\n        fi\n\n        # get the hash of the last llvm we built\n        # by downloading the existing .tgz (if any)\n        # and extracting the value from .halide_builder_llvm_commit.\n        # (This isn't very efficient, but that's ok.)\n        set +e\n        LLVM_OLD_COMMIT=bogus\n        curl --fail --user llvm_user:${{secrets.LLVM_USER_PASSWORD}} --output ${_ROOT}/old_llvm.tgz ${LLVM_INSTALL_URL}\n        if [ $? -eq 0 ]; then\n          LLVM_OLD_COMMIT=`${TAR_CMD} -O -xf ${_ROOT}/old_llvm.tgz ./${LLVM_COMMIT_HASH_FILE}`\n          if [ $? -ne 0 ]; then\n            LLVM_OLD_COMMIT=bogus_2\n          fi\n        fi\n        set -e\n\n        rm -rf ${_ROOT}/old_llvm.tgz\n\n        echo \"LLVM_OLD_COMMIT is ${LLVM_OLD_COMMIT}\"\n\n        # Clone current top of tree.\n        git clone https://github.com/llvm/llvm-project.git \\\n          \"${LLVM_SOURCE_DIR}\" \\\n          --branch ${{matrix.llvm_branch}} \\\n          --single-branch \\\n          --depth 1\n\n        # Find the new commit.\n        cd ${LLVM_SOURCE_DIR}\n        LLVM_NEW_COMMIT=`git rev-parse HEAD`\n\n        echo \"LLVM_NEW_COMMIT is ${LLVM_NEW_COMMIT}\"\n\n        NEED_REBUILD=0\n\n        echo \"github.event.action is ${{github.event.action}}\"\n        if [[ \"${{github.event.action}}\" == halide_llvm_builder_force_rebuild* ]]; then\n          # extract the second half; it is expected to be a glob pattern that is compared\n          # against LLVM_ID (so we can rebuild some or all), thus halide_llvm_builder_force_rebuild:*\n          # should rebuild all, halide_llvm_builder_force_rebuild:*osx* would rebuild all osx, etc\n          GLOB=`echo \"${{github.event.action}}\" | cut -d':' -f2`\n          if [[ ${LLVM_ID} == ${GLOB} ]]; then\n            echo \"LLVM_ID ${LLVM_ID} matches glob ${GLOB}, forcing rebuild\"\n            NEED_REBUILD=1\n          fi\n        fi\n\n        if [ ${LLVM_NEW_COMMIT} == ${LLVM_OLD_COMMIT} ]; then\n          echo \"LLVM is already up to date, no need to rebuild\"\n        else\n          echo \"LLVM commit mismatch, needs rebuilding!\"\n          NEED_REBUILD=1\n        fi\n\n        if ((NEED_REBUILD)); then\n          echo \"LLVM is being rebuilt!\"\n\n          LLVM_BUILD_32_BITS=$([ ${{matrix.target_bits}} == 32 ] && echo \"ON\" || echo \"OFF\")\n\n          CMAKE_GEN=\"Ninja\"\n          BUILD_TYPE=Release\n          EXTRA_CMAKE_FLAGS=\n          PARALLEL_JOBS=4  # GHA VMs have 2 cores\n\n          if [[ ${{matrix.host_os}} == windows* ]]; then\n            CMAKE_GEN=\"Visual Studio 16\"\n\n            EXTRA_CMAKE_FLAGS=\"${EXTRA_CMAKE_FLAGS} -T host=x64\"\n            if [[ ${{matrix.target_bits}} == 32 ]]; then\n              EXTRA_CMAKE_FLAGS=\"${EXTRA_CMAKE_FLAGS} -A Win32\"\n            else\n              EXTRA_CMAKE_FLAGS=\"${EXTRA_CMAKE_FLAGS} -A x64\"\n            fi\n\n            # TODO: LLVM_TEMPORARILY_ALLOW_OLD_TOOLCHAIN is temporary,\n            # until MSVC 16.5 is available on the GHA VMs\n            EXTRA_CMAKE_FLAGS=\"${EXTRA_CMAKE_FLAGS} \\\n                               -D LLVM_TEMPORARILY_ALLOW_OLD_TOOLCHAIN=ON\"\n          fi\n\n          if [[ ${{matrix.target_arch}} == x86 && \\\n                ${{matrix.target_os}} == linux && \\\n                ${{matrix.target_bits}} == 32 ]]; then\n            # Assume host_os is ubuntu*\n            EXTRA_CMAKE_FLAGS=\"${EXTRA_CMAKE_FLAGS} \\\n                               -D CMAKE_FIND_ROOT_PATH=/usr/lib/i386-linux-gnu \\\n                               -D CMAKE_FIND_ROOT_PATH_MODE_LIBRARY=ONLY\"\n            export CC=\"${CC} -m32\"\n            export CXX=\"${CXX} -m32\"\n            export LD=\"${LD} -melf_i386\"\n          fi\n\n          if [[ ${{matrix.target_os}} == macos* ]]; then\n            # LLVM_ENABLE_SUPPORT_XCODE_SIGNPOSTS=OFF is needed for compatibility with older XCode versions\n            EXTRA_CMAKE_FLAGS=\"${EXTRA_CMAKE_FLAGS} \\\n                               -D LLVM_ENABLE_SUPPORT_XCODE_SIGNPOSTS=FORCE_OFF\"\n          fi\n\n          if [[ ${{matrix.target_arch}} == arm ]]; then\n            # (Assume the host is Ubuntu)\n            #\n            # To cross-compile, we need llvm-tblgen and clang-tblgen in forms that will\n            # run on the host machine. We don't try to pull them from an install because\n            # (1) mixing tblgen builds between versions can be problematic, and\n            # (2) clang-tblgen isn't part of the install package (yes, this makes crosscompiling\n            # more painful than it needs to be). We're just build the two tools we need here;\n            # we'll only use these for bootstrapping, then discard them.\n            #\n            LLVM_TBLGEN_BUILD_DIR=\"${_ROOT}/${LLVM_ID}-tblgen\"\n            cmake \\\n                -D CMAKE_BUILD_TYPE=Release \\\n                -D LLVM_ENABLE_ASSERTIONS=ON \\\n                -D LLVM_ENABLE_PROJECTS=\"clang\" \\\n                -D LLVM_ENABLE_RTTI=OFF \\\n                -D LLVM_ENABLE_TERMINFO=OFF \\\n                -G Ninja \\\n                -B \"${LLVM_TBLGEN_BUILD_DIR}\" \\\n                -S \"${LLVM_SOURCE_DIR}/llvm\"\n            ninja -C ${LLVM_TBLGEN_BUILD_DIR} llvm-tblgen clang-tblgen\n\n            EXTRA_CMAKE_FLAGS=\"\\\n              -D CMAKE_CROSSCOMPILING=True \\\n              -D LLVM_TABLEGEN=${LLVM_TBLGEN_BUILD_DIR}/bin/llvm-tblgen \\\n              -D CLANG_TABLEGEN=${LLVM_TBLGEN_BUILD_DIR}/bin/clang-tblgen\"\n\n            if [[ ${{matrix.target_bits}} == 32 ]]; then\n              export CC=\"arm-linux-gnueabihf-${{matrix.cc}}\"\n              export CXX=\"arm-linux-gnueabihf-${{matrix.cxx}}\"\n              EXTRA_CMAKE_FLAGS=\"${EXTRA_CMAKE_FLAGS} \\\n                                -D LLVM_TARGET_ARCH=ARM \\\n                                -D LLVM_DEFAULT_TARGET_TRIPLE=arm-linux-gnueabihf\"\n            else\n              export CC=\"aarch64-linux-gnu-${{matrix.cc}}\"\n              export CXX=\"aarch64-linux-gnu-${{matrix.cxx}}\"\n              EXTRA_CMAKE_FLAGS=\"${EXTRA_CMAKE_FLAGS} \\\n                                 -D LLVM_TARGET_ARCH=AArch64 \\\n                                 -D LLVM_DEFAULT_TARGET_TRIPLE=aarch64-linux-gnu\"\n            fi\n          fi\n\n          cmake \\\n            -D CMAKE_BUILD_TYPE=${BUILD_TYPE} \\\n            -D CMAKE_INSTALL_PREFIX=\"${LLVM_INSTALL_DIR}\" \\\n            -D LLVM_BUILD_32_BITS=${LLVM_BUILD_32_BITS} \\\n            -D LLVM_ENABLE_ASSERTIONS=ON \\\n            -D LLVM_ENABLE_LIBXML2=OFF \\\n            -D LLVM_ENABLE_PROJECTS=\"clang;lld\" \\\n            -D LLVM_ENABLE_RTTI=ON \\\n            -D LLVM_ENABLE_TERMINFO=OFF \\\n            -D LLVM_TARGETS_TO_BUILD=\"X86;ARM;NVPTX;AArch64;Mips;PowerPC;Hexagon;WebAssembly\" \\\n            -G \"${CMAKE_GEN}\" \\\n            ${EXTRA_CMAKE_FLAGS} \\\n            -B \"${LLVM_BUILD_DIR}\" \\\n            -S \"${LLVM_SOURCE_DIR}/llvm\"\n\n          # Re-specifying --config here is essential\n          # to avoid Windows builds from building some subtargets\n          # in Debug mode and using up all available disk space\n          cmake \\\n            --build \"${LLVM_BUILD_DIR}\" \\\n            --config ${BUILD_TYPE} \\\n            -j ${PARALLEL_JOBS} \\\n            --target install\n\n          echo ${LLVM_NEW_COMMIT} > ${LLVM_INSTALL_DIR}/${LLVM_COMMIT_HASH_FILE}\n\n          cd ${LLVM_INSTALL_DIR}\n          ${TAR_CMD} -czf ${LLVM_INSTALL_TGZ} .\n\n          curl \\\n            --upload-file ${LLVM_INSTALL_TGZ} \\\n            --user llvm_user:${{secrets.LLVM_USER_PASSWORD}} \\\n            ${LLVM_INSTALL_URL}\n\n        fi\n\nfile: test.yml\nContent:\n# TODO (known issues)\n# - no GPU tests are attempted (probably not possible)\n# - cmake static builds aren't handled yet.\n# - arm32 and arm64 is build-only, no testing (qemu is too slow).\n#   Perhaps some limited testing instead of none?\n# - python is built+tested for x86-64 targets only (no arm or 32-bit)\n# - apps are skipped for x86-32, arm-32, arm-64\n#\n# TODO (stuff that could be usefully added, perhaps)\n# - build + test of WASM\n# - build + test of PyTorch\n#\n# TODO (GHA issues)\n# - GHA is occasionally flaky and some VMs just fail, but there isn't a way\n#   to restart just one of the jobs (it's currently all-or-none)\n\nname: Halide Presubmit Build + Test\non:\n  workflow_dispatch:\n    # inputs:\n    #   logLevel:\n    #     description: 'Log level'\n    #     required: true\n    #     default: 'warning'\n    #   tags:\n    #     description: 'Test scenario tags'\n\n  # pull_request:\n  #   # We don't want 'edited' (that's basically just the description, title, etc)\n  #   # We don't want 'review_requested' (that's redundant to the ones below for our purposes)\n  #   types: [opened, synchronize, reopened]\n  #   # TODO: do we want to limit this to certain filetypes?\n  #   # paths:\n  #   #   - '**.h'\n  #   #   - '**.c'\n  #   #   - '**.cpp'\n\njobs:\n  test_halide:\n    name: HL-${{matrix.llvm_version}}-${{matrix.target_arch}}-${{matrix.target_bits}}-${{matrix.target_os}}-${{matrix.build_tool}}\n    runs-on: ${{matrix.host_os}}\n    env:\n      CC: ${{matrix.cc}}\n      CXX: ${{matrix.cxx}}\n      LD: ${{matrix.ld}}\n\n    strategy:\n      fail-fast: false  # Keep running other jobs even if one fails\n      # free-tier projects (like Halide) get 20 concurrent tasks.\n      # The build matrix here has only 7 tasks -- should we limit it to fewer\n      # than that? Need to experiment.\n      # max-parallel: TBD   TODO\n      matrix:\n        # TODO: this matrix is probably overkill; we don't need to build every combination.\n        # (Some combinations are nonsensical and excluded via the 'exclude:' section below.)\n        target_arch: [x86, arm]\n        target_bits: [32, 64]\n        target_os: [linux, osx, windows]\n        llvm_version: [12]\n        build_tool: [cmake_shared]\n        # llvm_version: [10, 11, 12]  # TODO\n        # build_tool: [cmake_shared, make]  # TODO\n\n        # This section basically allows us to define additional values for\n        # each matrix entry, e.g. to map an llvm version number to the specific\n        # git branch that is needed.\n        include:\n          # - llvm_version: 10\n          #   llvm_branch: release/10.x\n          # - llvm_version: 11\n          #   llvm_branch: release/11.x\n          - llvm_version: 12\n            llvm_branch: master\n\n          # map things to the necessary host cross-compiler host\n          - target_os: osx\n            host_os: macos-10.15\n            cc: clang\n            cxx: clang++\n            ld: ld\n\n          - target_os: linux\n            host_os: ubuntu-18.04\n            # GHA has clang 6, 8, and 9 and GCC 7.4, 8.3, 9.2 preinstalled.\n            # We will explicitly choose gcc 7.x (even though the default is gcc 7.4)\n            # to ensure we match gcc versions with the arm crosscompiler.\n            cc: gcc-7\n            cxx: g++-7\n            ld: ld\n\n          - target_os: windows\n            host_os: windows-2019\n            cc: cl.exe\n            cxx: cl.exe\n            ld: ld.exe\n\n          - target_arch: x86\n            python_version: '3.7'\n            uses_python: true\n            run_tests: true\n\n          - target_bits: 32\n            # We don't build/test Python bindings on any 32-bit targets\n            uses_python: false\n\n          - target_arch: arm\n            # We don't build/test Python bindings on any ARM targets\n            uses_python: false\n            # Running our test suite (via e.g. QEMU) is too slow to be useful\n            # at present (> 5 hours on current GHA VMs). That said, we'll leave\n            # in the relevant code for now (disabled via this flag) in case\n            # it proves useful later.\n            run_tests: false\n\n        exclude:\n          - target_os: osx\n            target_arch: arm    # OSX is x86-only\n          - target_os: osx\n            target_bits: 32     # OSX is 64-bit only\n          - target_os: windows\n            target_arch: arm    # OSX is x86-only\n          - target_os: windows\n            build_tool: make    # Windows is CMake-only\n          - target_arch: arm\n            build_tool: make    # In this setup, all ARM builds require CMake\n\n    steps:\n    - uses: actions/checkout@v2\n      with:\n        path: 'halide'\n\n    - name: Configure Python\n      if: matrix.uses_python\n      uses: actions/setup-python@v1\n      with:\n        python-version: '${{matrix.python_version}}'\n        architecture: 'x64'\n\n    - name: Configure Ubuntu Host\n      if: startsWith(matrix.host_os, 'ubuntu')\n      shell: bash\n      run: |\n        sudo apt-get update\n\n        sudo apt-get install \\\n          doxygen \\\n          libjpeg-dev \\\n          libpng-dev \\\n          ninja-build\n\n        # TODO(srj): OpenGL is only needed to build the opengl tests (which we don't even run)...\n        sudo apt-get install \\\n          freeglut3-dev \\\n          libglu1-mesa-dev \\\n          mesa-common-dev\n\n    - name: Configure MacOS Host\n      if: startsWith(matrix.host_os, 'macos')\n      shell: bash\n      run: |\n        # coreutils is for gtimeout\n        brew install \\\n          coreutils \\\n          doxygen \\\n          jpeg \\\n          libpng \\\n          ninja\n\n    - name: Configure Windows Host\n      if: startsWith(matrix.host_os, 'windows')\n      shell: bash\n      run: |\n        if [[ ${{matrix.target_bits}} == 32 ]]; then\n          export VCPKG_DEFAULT_TRIPLET=x86-windows\n        else\n          export VCPKG_DEFAULT_TRIPLET=x64-windows\n        fi\n\n        vcpkg install \\\n          libjpeg-turbo \\\n          libpng \\\n          zlib\n\n    - name: Configure x86-32 Crosscompilation\n      if: matrix.target_os == 'linux' && matrix.target_arch == 'x86' && matrix.target_bits == 32\n      shell: bash\n      run: |\n        sudo dpkg --add-architecture i386\n        sudo apt-get update\n        sudo apt-get install \\\n          ${{matrix.cc}}-multilib \\\n          ${{matrix.cxx}}-multilib \\\n          libjpeg-dev:i386 \\\n          libpng-dev:i386 \\\n\n        # TODO(srj): OpenGL is only needed to build the opengl tests (which we don't even run)...\n        sudo apt-get install \\\n          freeglut3-dev:i386 \\\n          libglu1-mesa-dev:i386 \\\n          mesa-common-dev:i386\n\n    - name: Configure Arm32 Crosscompilation\n      if: matrix.target_os == 'linux' && matrix.target_arch == 'arm' && matrix.target_bits == 32\n      shell: bash\n      run: |\n        # Note that we are configuring this for user-mode emulation:\n        # syscalls will be native, only user-mode code will be emulated.\n        # This is not 100% perfect (there are various corner cases that\n        # can bite us), but is *much* faster than full machine emulation.\n\n        sudo apt-get update\n        sudo apt-get install --install-suggests \\\n          ${{matrix.cc}}-arm-linux-gnueabihf \\\n          ${{matrix.cxx}}-arm-linux-gnueabihf\n\n        # TODO: figure out how to install libjpeg and libpng for armhf;\n        # the standard apt repository for GHA VMs barfs on these.\n        # sudo apt-get install \\\n        #   libjpeg-dev:armhf \\\n        #   libpng-dev:armhf\n\n        # Note that we need QEMU even if not running tests, as Generators\n        # will be built for arm by default, and we need to be able to run them.\n        sudo apt-get install --install-suggests \\\n          qemu-user \\\n          qemu-user-binfmt\n\n        qemu-arm --version\n        echo ::set-env name=QEMU_LD_PREFIX::\"/usr/arm-linux-gnueabihf\"\n\n    - name: Configure AArch64 Crosscompilation\n      if: matrix.target_os == 'linux' && matrix.target_arch == 'arm' && matrix.target_bits == 64\n      shell: bash\n      run: |\n        sudo apt-get update\n        sudo apt-get install --install-suggests \\\n          ${{matrix.cc}}-aarch64-linux-gnu \\\n          ${{matrix.cxx}}-aarch64-linux-gnu\n\n        # TODO: figure out how to install libjpeg and libpng for armhf;\n        # the standard apt repository for GHA VMs barfs on these.\n        # sudo apt-get install \\\n        #   libjpeg-dev:aarch64 \\\n        #   libpng-dev:aarch64\n\n        # Note that we need QEMU even if not running tests, as Generators\n        # will be built for arm by default, and we need to be able to run them.\n        sudo apt-get install --install-suggests \\\n          qemu-user \\\n          qemu-user-binfmt\n\n        qemu-arm --version\n        echo ::set-env name=QEMU_LD_PREFIX::\"/usr/aarch64-linux-gnu\"\n\n    - name: Configure Env Vars\n      shell: bash\n      run: |\n        echo \"github.event_name is ${{github.event_name}}\"  # should always be \"pull_request\"\n        echo \"github.event.action is ${{github.event.action}}\"\n\n        # Demangle Windows names, to simplify CMake stuff later\n        _ROOT=${GITHUB_WORKSPACE//\\\\//}\n        _TEMP_RAW=\"${{runner.temp}}\"\n        _TEMP=${_TEMP_RAW//\\\\//}\n\n        # This is the trick GitHub Actions uses to allow us to set env vars across all subsequent job steps\n        echo ::set-env name=BUILD_TYPE::\"Release\"\n        echo ::set-env name=LLVM_INSTALL_DIR::\"${_ROOT}/llvm\"\n        echo ::set-env name=LLVM_CONFIG::\"${_ROOT}/llvm/bin/llvm-config\"\n        echo ::set-env name=HALIDE_SOURCE_DIR::\"${_ROOT}/halide\"\n        echo ::set-env name=HALIDE_BUILD_DIR::\"${_ROOT}/halide_build\"\n        echo ::set-env name=HALIDE_TEMP_DIR::\"${_TEMP}\"\n        echo ::set-env name=PARALLEL_JOBS::\"4\"\n        if [[ ${{matrix.host_os}} == windows* ]]; then\n          # On Windows, it's just 'python', apparently\n          echo ::set-env name=PYTHON::\"python\"\n        else\n          echo ::set-env name=PYTHON::\"python${{matrix.python_version}}\"\n        fi\n\n    - name: Install Python Dependencies\n      if: matrix.uses_python\n      shell: bash\n      run: |\n        ${PYTHON} -m pip --version\n        ${PYTHON} -m pip install --upgrade pip\n        ${PYTHON} -m pip install -r ${HALIDE_SOURCE_DIR}/python_bindings/requirements.txt\n\n        echo ::set-env name=PYTHON::\"${PYTHON}\"\n\n    - name: Install LLVM\n      shell: bash\n      run: |\n        LLVM_ID=\"llvm-${{matrix.llvm_version}}-${{matrix.target_arch}}-${{matrix.target_bits}}-${{matrix.target_os}}\"\n\n        curl \\\n          --user llvm_user:${{secrets.LLVM_USER_PASSWORD}} \\\n          --output ${HALIDE_TEMP_DIR}/llvm-prebuilt.tgz \\\n          https://buildbot.halide-lang.org/llvm/${LLVM_ID}.tgz\n\n        TAR_CMD=\"tar\"\n        if [[ ${{matrix.host_os}} == windows* ]]; then\n          # Must use --force-local to avoid tar misinterpreting the : in\n          # a Windows pathname as a hostname.\n          TAR_CMD=\"tar --force-local\"\n        fi\n\n        mkdir ${LLVM_INSTALL_DIR}\n        ${TAR_CMD} -xf ${HALIDE_TEMP_DIR}/llvm-prebuilt.tgz -C ${LLVM_INSTALL_DIR}\n        rm -rf ${HALIDE_TEMP_DIR}/llvm-prebuilt.tgz\n\n        LLVM_COMMIT_HASH=`cat ${LLVM_INSTALL_DIR}/.halide_builder_llvm_commit`\n        echo \"Using LLVM v${{matrix.llvm_version}} commit=${LLVM_COMMIT_HASH}\"\n\n    - name: Configure Halide (Make)\n      if: startsWith(matrix.build_tool, 'make')\n      shell: bash\n      run: |\n        # Configure Make\n        mkdir ${HALIDE_BUILD_DIR}\n\n        if [[ ${{matrix.target_arch}} == x86 && \\\n              ${{matrix.target_os}} == linux && \\\n              ${{matrix.target_bits}} == 32 ]]; then\n          echo ::set-env name=CC::\"${CC} -m32\"\n          echo ::set-env name=CXX::\"${CXX} -m32\"\n          echo ::set-env name=LD::\"${LD} -melf_i386\"\n        fi\n\n    - name: Configure Halide (CMake)\n      if: startsWith(matrix.build_tool, 'cmake')\n      shell: bash\n      run: |\n        # Configure CMake\n        echo `cmake --version`\n\n        mkdir ${HALIDE_BUILD_DIR}\n\n        CMAKE_GEN=\"Ninja\"\n        EXTRA_CMAKE_FLAGS=\n\n        if [[ ${{matrix.host_os}} == windows* ]]; then\n          CMAKE_GEN=\"Visual Studio 16 2019\"\n\n          # CMAKE_TOOLCHAIN_FILE is necessary for CMake to find things installed by vcpkg\n          EXTRA_CMAKE_FLAGS=\"${EXTRA_CMAKE_FLAGS} \\\n            -D CMAKE_TOOLCHAIN_FILE=${VCPKG_INSTALLATION_ROOT//\\\\//}/scripts/buildsystems/vcpkg.cmake \\\n            -T host=x64\"\n          if [[ ${{matrix.target_bits}} == 32 ]]; then\n            EXTRA_CMAKE_FLAGS=\"${EXTRA_CMAKE_FLAGS} -A Win32\"\n          else\n            EXTRA_CMAKE_FLAGS=\"${EXTRA_CMAKE_FLAGS} -A x64\"\n          fi\n        fi\n\n        if [[ ${{matrix.target_arch}} == x86 && \\\n              ${{matrix.target_os}} == linux && \\\n              ${{matrix.target_bits}} == 32 ]]; then\n          # Assume host_os is ubuntu*\n          EXTRA_CMAKE_FLAGS=\"${EXTRA_CMAKE_FLAGS} \\\n            -D CMAKE_TOOLCHAIN_FILE=${HALIDE_SOURCE_DIR}/cmake/toolchain.linux-i386.cmake\"\n        fi\n\n        if [[ ${{matrix.target_os}} == osx ]]; then\n          # LLVM_ENABLE_SUPPORT_XCODE_SIGNPOSTS=OFF is needed for compatibility with older XCode versions\n          EXTRA_CMAKE_FLAGS=\"${EXTRA_CMAKE_FLAGS} \\\n                             -D LLVM_ENABLE_SUPPORT_XCODE_SIGNPOSTS=FORCE_OFF\"\n        fi\n\n        if [[ ${{matrix.target_arch}} == arm ]]; then\n          # The arm toolchain files default to \"gcc\"/\"g++\" with no version appended,\n          # but we installed specific versions, so be sure it can find those specific versions.\n          if [[ ${{matrix.target_bits}} == 32 ]]; then\n            export ARCH_FOR_TESTS=armv7-a\n            EXTRA_CMAKE_FLAGS=\"${EXTRA_CMAKE_FLAGS} \\\n              -D CMAKE_C_COMPILER=arm-linux-gnueabihf-${{matrix.cc}} \\\n              -D CMAKE_CXX_COMPILER=arm-linux-gnueabihf-${{matrix.cxx}} \\\n              -D CMAKE_TOOLCHAIN_FILE=${HALIDE_SOURCE_DIR}/cmake/toolchain.linux-arm32.cmake\"\n          else\n            export ARCH_FOR_TESTS=armv8-a\n            EXTRA_CMAKE_FLAGS=\"${EXTRA_CMAKE_FLAGS} \\\n              -D CMAKE_C_COMPILER=aarch64-linux-gnu-${{matrix.cc}} \\\n              -D CMAKE_CXX_COMPILER=aarch64-linux-gnu-${{matrix.cxx}} \\\n              -D CMAKE_TOOLCHAIN_FILE=${HALIDE_SOURCE_DIR}/cmake/toolchain.linux-aarch64.cmake\"\n          fi\n        fi\n\n        REQUIRE_LLVM_VERSION=\"${{matrix.llvm_version}}0\"\n        SHARED_LIBRARY=$([ ${{matrix.build_tool}} == \"cmake_shared\" ] && echo \"ON\" || echo \"OFF\")\n\n        if [[ \"${{matrix.uses_python}}\" == \"true\" ]]; then\n          EXTRA_CMAKE_FLAGS=\"${EXTRA_CMAKE_FLAGS} \\\n            -D WITH_PYTHON_BINDINGS=ON\"\n        else\n          EXTRA_CMAKE_FLAGS=\"${EXTRA_CMAKE_FLAGS} \\\n            -D WITH_PYTHON_BINDINGS=OFF\"\n        fi\n\n        cmake \\\n          -D CMAKE_BUILD_TYPE=${BUILD_TYPE} \\\n          -D LLVM_DIR=\"${LLVM_INSTALL_DIR}/lib/cmake/llvm\" \\\n          -D HALIDE_REQUIRE_LLVM_VERSION=\"${REQUIRE_LLVM_VERSION}\" \\\n          -D HALIDE_SHARED_LIBRARY=${SHARED_LIBRARY} \\\n          -G \"${CMAKE_GEN}\" \\\n          ${EXTRA_CMAKE_FLAGS} \\\n          -S \"${HALIDE_SOURCE_DIR}\" \\\n          -B \"${HALIDE_BUILD_DIR}\"\n\n    - name: Build Halide (Make)\n      if: startsWith(matrix.build_tool, 'make')\n      shell: bash\n      run: |\n        # Build Halide\n        cd ${HALIDE_BUILD_DIR}\n\n        BUILD_TARGETS=\"distrib build_tests\"\n        if [[ \"${{matrix.uses_python}}\" == \"true\" ]]; then\n          # build_apps requires the python bindings\n          BUILD_TARGETS=\"${BUILD_TARGETS} build_apps build_python_bindings\"\n        fi\n\n        make -f ${HALIDE_SOURCE_DIR}/Makefile -j ${PARALLEL_JOBS} ${BUILD_TARGETS}\n\n    - name: Build Halide (CMake)\n      if: startsWith(matrix.build_tool, 'cmake')\n      shell: bash\n      run: |\n        # Build Halide\n        cd ${HALIDE_BUILD_DIR}\n        cmake \\\n          --build ${HALIDE_BUILD_DIR} \\\n          --config ${BUILD_TYPE} \\\n          -j ${PARALLEL_JOBS}\n\n    - name: Run Tests (Make)\n      if: matrix.run_tests && startsWith(matrix.build_tool, 'make')\n      shell: bash\n      run: |\n        # Test Halide\n        export TEST_TMPDIR=\"${HALIDE_TEMP_DIR}\"\n        cd ${HALIDE_BUILD_DIR}\n\n        TEST_GROUPS_PARALLEL=\"internal correctness error warning generator\"\n        if [[ \"${{matrix.uses_python}}\" == \"true\" ]]; then\n          TEST_GROUPS_PARALLEL=\"${TEST_GROUPS_PARALLEL} python\"\n        fi\n\n        # tutorial has some performance measurements that can be flaky if we run them in parallel\n        TEST_GROUPS_SERIAL=\"tutorial\"\n\n        # performance is never going to be reliable on VMs.\n        # opengl won't work on the buildbots.\n        # auto_schedule is just flaky.\n        TEST_GROUPS_BROKEN=\"performance opengl auto_schedule\"\n\n        if [[ ${{matrix.target_bits}} == 32 ]]; then\n          # TODO: Skip testing apps on 32-bit systems for now;\n          # in particular, apps/autoscheduler can time out, and also has build\n          # issues on ubuntu-32 at the moment (__udivdi3).\n          TEST_GROUPS_BROKEN=\"${TEST_GROUPS_BROKEN} apps\"\n        else\n          TEST_GROUPS_PARALLEL=\"${TEST_GROUPS_PARALLEL} apps\"\n        fi\n\n        # Parallel\n        for t in ${TEST_GROUPS_PARALLEL}; do\n          make -f ${HALIDE_SOURCE_DIR}/Makefile -j ${PARALLEL_JOBS} test_${t}\n        done\n\n        # Serial\n        for t in ${TEST_GROUPS_SERIAL}; do\n          make -f ${HALIDE_SOURCE_DIR}/Makefile test_$t\n        done\n\n    - name: Run Tests (CMake)\n      if: matrix.run_tests && startsWith(matrix.build_tool, 'cmake')\n      shell: bash\n      run: |\n        # Test Halide\n        TEST_GROUPS_PARALLEL=\"internal|correctness|error|warning|generator\"\n\n        if [[ \"${{matrix.uses_python}}\" == \"true\" ]]; then\n          TEST_GROUPS_PARALLEL=\"${TEST_GROUPS_PARALLEL}|python\"\n        fi\n\n        # tutorial has some performance measurements that can be flaky if we run them in parallel\n        TEST_GROUPS_SERIAL=\"tutorial\"\n\n        # performance is never going to be reliable on VMs.\n        # opengl won't work on the buildbots.\n        # auto_schedule is just flaky.\n        TEST_GROUPS_BROKEN=\"performance|opengl|auto_schedule\"\n\n        export TEST_TMPDIR=\"${HALIDE_TEMP_DIR}\"\n        cd ${HALIDE_BUILD_DIR}\n\n        # Parallel\n        ctest \\\n          -C ${BUILD_TYPE} \\\n          -j ${PARALLEL_JOBS} \\\n          -L \"${TEST_GROUPS_PARALLEL}\" \\\n          --output-on-failure\n\n        # Serial\n        ctest \\\n          -C ${BUILD_TYPE} \\\n          -L \"${TEST_GROUPS_SERIAL}\" \\\n          -E \"${TEST_GROUPS_BROKEN}\" \\\n          --output-on-failure\n",
    "readme": "# Halide\n\nHalide is a programming language designed to make it easier to write\nhigh-performance image and array processing code on modern machines. Halide\ncurrently targets:\n\n- CPU architectures: X86, ARM, MIPS, Hexagon, PowerPC\n- Operating systems: Linux, Windows, Mac OS X, Android, iOS, Qualcomm QuRT\n- GPU Compute APIs: CUDA, OpenCL, OpenGL, OpenGL Compute Shaders, Apple Metal,\n  Microsoft Direct X 12\n\nRather than being a standalone programming language, Halide is embedded in C++.\nThis means you write C++ code that builds an in-memory representation of a\nHalide pipeline using Halide's C++ API. You can then compile this representation\nto an object file, or JIT-compile it and run it in the same process. Halide also\nprovides a Python binding that provides full support for writing Halide embedded\nin Python without C++.\n\nFor more detail about what Halide is, see http://halide-lang.org.\n\nFor API documentation see http://halide-lang.org/docs\n\nTo see some example code, look in the tutorials directory.\n\nIf you've acquired a full source distribution and want to build Halide, see the\n[notes below](#building-halide-with-cmake).\n\n# Getting Halide\n\n## Binary tarballs\n\nThe latest version of Halide is **Halide 10.0.0**. We provide binary releases\nfor many popular platforms and architectures, including 32/64-bit x86 Windows,\n64-bit macOS, and 32/64-bit x86/ARM Ubuntu Linux. See the releases tab on the\nright (or click [here](https://github.com/halide/Halide/releases/tag/v10.0.0)).\n\n## Vcpkg\n\nIf you use [vcpkg](https://github.com/microsoft/vcpkg) to manage dependencies,\nyou can install Halide via:\n\n```\n$ vcpkg install halide:x64-windows # or x64-linux/x64-osx\n```\n\nNote two caveats: first, at time of writing,\n[MSVC mis-compiles LLVM](https://github.com/halide/Halide/issues/5039) on\nx86-windows, so Halide cannot be used in vcpkg on that platform at this time;\nsecond, vcpkg installs only the minimum Halide backends required to compile code\nfor the active platform. If you want to include all the backends, you should\ninstall `halide[target-all]:x64-windows` instead. Note that since this will\nbuild LLVM, it will take a _lot_ of disk space (up to 100GB).\n\n## Homebrew\n\nAlternatively, if you use macOS, you can install Halide via\n[Homebrew](https://brew.sh/) like so:\n\n```\n$ brew install halide\n```\n\n## Other package managers\n\nWe are interested in bringing Halide 10 to other popular package managers\nand Linux distribution repositories including, but not limited to, Conan,\nDebian, [Ubuntu (or PPA)](https://github.com/halide/Halide/issues/5285),\nCentOS/Fedora, and Arch. If you have experience publishing packages we\nwould be happy to work with you!\n\nIf you are a maintainer of any other package distribution platform, we would\nbe excited to work with you, too.\n\n# Building Halide with Make\n\n### TL;DR\n\nHave llvm-9.0 (or greater) installed and run `make` in the root directory of the\nrepository (where this README is).\n\n### Acquiring LLVM\n\nAt any point in time, building Halide requires either the latest stable version\nof LLVM, the previous stable version of LLVM, and trunk. At the time of writing,\nthis means versions 11.0 and 10.0 are supported, but 9.0 is not. The commands\n`llvm-config` and `clang` must be somewhere in the path.\n\nIf your OS does not have packages for llvm, you can find binaries for it at\nhttp://llvm.org/releases/download.html. Download an appropriate package and then\neither install it, or at least put the `bin` subdirectory in your path. (This\nworks well on OS X and Ubuntu.)\n\nIf you want to build it yourself, first check it out from GitHub:\n\n```\n% git clone --depth 1 --branch llvmorg-11.0.0 https://github.com/llvm/llvm-project.git\n```\n\n(If you want to build LLVM 10.x, use branch `llvmorg-10.0.1`; for current trunk,\nuse `master`)\n\nThen build it like so:\n\n```\n% cmake -DCMAKE_BUILD_TYPE=Release \\\n        -DLLVM_ENABLE_PROJECTS=\"clang;lld;clang-tools-extra\" \\\n        -DLLVM_TARGETS_TO_BUILD=\"X86;ARM;NVPTX;AArch64;Mips;Hexagon\" \\\n        -DLLVM_ENABLE_TERMINFO=OFF -DLLVM_ENABLE_ASSERTIONS=ON \\\n        -DLLVM_ENABLE_EH=ON -DLLVM_ENABLE_RTTI=ON -DLLVM_BUILD_32_BITS=OFF \\\n        -S llvm-project/llvm -B llvm-build\n% cmake --build llvm-build\n% cmake --install llvm-build --prefix llvm-install\n```\n\nthen to point Halide to it:\n\n```\n% export LLVM_ROOT=$PWD/llvm-install\n% export LLVM_CONFIG=$LLVM_ROOT/bin/llvm-config\n```\n\nNote that you _must_ add `clang` to `LLVM_ENABLE_PROJECTS`; adding `lld` to\n`LLVM_ENABLE_PROJECTS` is only required when using WebAssembly, and adding\n`clang-tools-extra` is only necessary if you plan to contribute code to Halide\n(so that you can run clang-tidy on your pull requests). We recommend enabling\nboth in all cases, to simplify builds. You can disable exception handling (EH)\nand RTTI if you don't want the Python bindings.\n\n### Building Halide with make\n\nWith `LLVM_CONFIG` set (or `llvm-config` in your path), you should be able to\njust run `make` in the root directory of the Halide source tree.\n`make run_tests` will run the JIT test suite, and `make test_apps` will make\nsure all the apps compile and run (but won't check their output).\n\nThere is no `make install` yet. If you want to make an install package, run\n`make distrib`.\n\n### Building Halide out-of-tree with make\n\nIf you wish to build Halide in a separate directory, you can do that like so:\n\n    % cd ..\n    % mkdir halide_build\n    % cd halide_build\n    % make -f ../Halide/Makefile\n\n# Building Halide with CMake\n\n### MacOS and Linux\n\nFollow the above instructions to build LLVM or acquire a suitable binary\nrelease. Then change directory to the Halide repository and run:\n\n```\n% cmake -DCMAKE_BUILD_TYPE=Release -DLLVM_DIR=$LLVM_ROOT/lib/cmake/llvm -S . -B build\n% cmake --build build\n```\n\n`LLVM_DIR` is the folder in the LLVM installation tree **(do not use the build\ntree by mistake)** that contains `LLVMConfig.cmake`. It is not required to set\nthis variable if you have a suitable system-wide version installed. If you have\nmultiple system-wide versions installed, you can specify the version with\n`Halide_REQUIRE_LLVM_VERSION`. Add `-G Ninja` if you prefer to build with the\nNinja generator.\n\n### Windows\n\nWe suggest building with Visual Studio 2019. Your mileage may vary with earlier\nversions. Be sure to install the \"C++ CMake tools for Windows\" in the Visual\nStudio installer. For older versions of Visual Studio, do not install the CMake\ntools, but instead acquire CMake and Ninja from their respective project\nwebsites.\n\nThese instructions start from the `D:` drive. We assume this git repo is cloned\nto `D:\\Halide`. We also assume that your shell environment is set up correctly.\nFor a 64-bit build, run:\n\n```\nD:\\> \"C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Auxiliary\\Build\\vcvarsall.bat\" x64\n```\n\nFor a 32-bit build, run:\n\n```\nD:\\> \"C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Auxiliary\\Build\\vcvarsall.bat\" x64_x86\n```\n\n#### Managing dependencies with vcpkg\n\nThe best way to get compatible dependencies on Windows is to use\n[vcpkg](https://github.com/Microsoft/vcpkg). Install it like so:\n\n```\nD:\\> git clone https://github.com/Microsoft/vcpkg.git\nD:\\> cd vcpkg\nD:\\> .\\bootstrap-vcpkg.bat\nD:\\vcpkg> .\\vcpkg integrate install\n...\nCMake projects should use: \"-DCMAKE_TOOLCHAIN_FILE=D:/vcpkg/scripts/buildsystems/vcpkg.cmake\"\n```\n\nThen install the libraries. For a 64-bit build, run:\n\n```\nD:\\vcpkg> .\\vcpkg install libpng:x64-windows libjpeg-turbo:x64-windows llvm[target-all,clang-tools-extra]:x64-windows\n```\n\nTo support 32-bit builds, also run:\n\n```\nD:\\vcpkg> .\\vcpkg install libpng:x86-windows libjpeg-turbo:x86-windows llvm[target-all,clang-tools-extra]:x86-windows\n```\n\n#### Building Halide\n\nCreate a separate build tree and call CMake with vcpkg's toolchain. This will\nbuild in either 32-bit or 64-bit depending on the environment script (`vcvars`)\nthat was run earlier.\n\n```\nD:\\Halide> cmake -G Ninja ^\n                 -DCMAKE_BUILD_TYPE=Release ^\n                 -DCMAKE_TOOLCHAIN_FILE=D:/vcpkg/scripts/buildsystems/vcpkg.cmake ^\n                 -S . -B build\n```\n\n**Note:** If building with Python bindings on 32-bit (enabled by default), be\nsure to point CMake to the installation path of a 32-bit Python 3. You can do\nthis by specifying, for example:\n`\"-DPython3_ROOT_DIR=C:\\Program Files (x86)\\Python38-32\"`.\n\nThen run the build with:\n\n```\nD:\\Halide> cmake --build build --config Release -j %NUMBER_OF_PROCESSORS%\n```\n\nTo run all the tests:\n\n```\nD:\\Halide> cd build\nD:\\Halide\\build> ctest -C Release\n```\n\nSubsets of the tests can be selected with `-L` and include `correctness`,\n`python`, `error`, and the other directory names under `/tests`.\n\n#### Building LLVM (optional)\n\nFollow these steps if you want to build LLVM yourself. First, download LLVM's\nsources (these instructions use the latest 11.0 release)\n\n```\nD:\\> git clone --depth 1 --branch llvmorg-11.0.0 https://github.com/llvm/llvm-project.git\n```\n\nFor a 64-bit build, run:\n\n```\nD:\\> cmake -G Ninja ^\n           -DCMAKE_BUILD_TYPE=Release ^\n           -DLLVM_ENABLE_PROJECTS=clang;lld;clang-tools-extra ^\n           -DLLVM_ENABLE_TERMINFO=OFF ^\n           -DLLVM_TARGETS_TO_BUILD=X86;ARM;NVPTX;AArch64;Mips;Hexagon ^\n           -DLLVM_ENABLE_ASSERTIONS=ON ^\n           -DLLVM_ENABLE_EH=ON ^\n           -DLLVM_ENABLE_RTTI=ON ^\n           -DLLVM_BUILD_32_BITS=OFF ^\n           -S llvm-project\\llvm -B llvm-build\n```\n\nFor a 32-bit build, run:\n\n```\nD:\\> cmake -G Ninja ^\n           -DCMAKE_BUILD_TYPE=Release ^\n           -DLLVM_ENABLE_PROJECTS=clang;lld;clang-tools-extra ^\n           -DLLVM_ENABLE_TERMINFO=OFF ^\n           -DLLVM_TARGETS_TO_BUILD=X86;ARM;NVPTX;AArch64;Mips;Hexagon ^\n           -DLLVM_ENABLE_ASSERTIONS=ON ^\n           -DLLVM_ENABLE_EH=ON ^\n           -DLLVM_ENABLE_RTTI=ON ^\n           -DLLVM_BUILD_32_BITS=ON ^\n           -S llvm-project\\llvm -B llvm32-build\n```\n\nFinally, run:\n\n```\nD:\\> cmake --build llvm-build --config Release -j %NUMBER_OF_PROCESSORS%\nD:\\> cmake --install llvm-build --prefix llvm-install\n```\n\nYou can substitute `Debug` for `Release` in the above `cmake` commands if you\nwant a debug build. Make sure to add `-DLLVM_DIR=D:/llvm-install/lib/cmake/llvm`\nto the Halide CMake command to override `vcpkg`'s LLVM.\n\n**MSBuild:** If you want to build LLVM with MSBuild instead of Ninja, use\n`-G \"Visual Studio 16 2019\" -Thost=x64 -A x64` or\n`-G \"Visual Studio 16 2019\" -Thost=x64 -A Win32` in place of `-G Ninja`.\n\n#### If all else fails...\n\nDo what the build-bots do: https://buildbot.halide-lang.org/master/#/builders\n\nIf the column that best matches your system is red, then maybe things aren't\njust broken for you. If it's green, then you can click the \"stdio\" links in the\nlatest build to see what commands the build bots run, and what the output was.\n\n# Some useful environment variables\n\n`HL_TARGET=...` will set Halide's AOT compilation target.\n\n`HL_JIT_TARGET=...` will set Halide's JIT compilation target.\n\n`HL_DEBUG_CODEGEN=1` will print out pseudocode for what Halide is compiling.\nHigher numbers will print more detail.\n\n`HL_NUM_THREADS=...` specifies the number of threads to create for the thread\npool. When the async scheduling directive is used, more threads than this number\nmay be required and thus allocated. A maximum of 256 threads is allowed. (By\ndefault, the number of cores on the host is used.)\n\n`HL_TRACE_FILE=...` specifies a binary target file to dump tracing data into\n(ignored unless at least one `trace_` feature is enabled in `HL_TARGET` or\n`HL_JIT_TARGET`). The output can be parsed programmatically by starting from the\ncode in `utils/HalideTraceViz.cpp`.\n\n# Using Halide on OSX\n\nPrecompiled Halide distributions are built using XCode's command-line tools with\nApple clang 500.2.76. This means that we link against libc++ instead of\nlibstdc++. You may need to adjust compiler options accordingly if you're using\nan older XCode which does not default to libc++.\n\n# Halide OpenGL/GLSL backend\n\nHalide's OpenGL backend offloads image processing operations to the GPU by\ngenerating GLSL-based fragment shaders.\n\nCompared to other GPU-based processing options such as CUDA and OpenCL, OpenGL\nhas two main advantages: it is available on basically every desktop computer and\nmobile device, and it is generally well supported across different hardware\nvendors.\n\nThe main disadvantage of OpenGL as an image processing framework is that the\ncomputational capabilities of fragment shaders are quite restricted. In general,\nthe processing model provided by OpenGL is most suitable for filters where each\noutput pixel can be expressed as a simple function of the input pixels. This\ncovers a wide range of interesting operations like point-wise filters and\nconvolutions; but a few common image processing operations such as histograms or\nrecursive filters are notoriously hard to express in GLSL.\n\n#### Writing OpenGL-Based Filters\n\nTo enable code generation for OpenGL, include `opengl` in the target specifier\npassed to Halide. Since OpenGL shaders are limited in their computational power,\nyou must also specify a CPU target for those parts of the filter that cannot or\nshould not be computed on the GPU. Examples of valid target specifiers are\n\n```\nhost-opengl\nx86-opengl-debug\n```\n\nAdding `debug`, as in the second example, adds additional logging output and is\nhighly recommended during development.\n\nBy default, filters compiled for OpenGL targets run completely on the CPU.\nExecution on the GPU must be enabled for individual Funcs by appropriate\nscheduling calls.\n\nGLSL fragment shaders implicitly iterate over two spatial dimensions x,y and the\ncolor channel. Due to the way color channels handled in GLSL, only filters for\nwhich the color index is a compile-time constant can be scheduled. The main\nconsequence is that the range of color variables must be explicitly specified\nfor both input and output buffers before scheduling:\n\n```\nImageParam input;\nFunc f;\nVar x, y, c;\nf(x, y, c) = ...;\n\ninput.set_bounds(2, 0, 3);   // specify color range for input\nf.bound(c, 0, 3);            // and output\nf.glsl(x, y, c);\n```\n\n#### JIT Compilation\n\nFor JIT compilation Halide attempts to load the system libraries for opengl and\ncreates a new context to use for each module. Windows is not yet supported.\n\nExamples for JIT execution of OpenGL-based filters can be found in test/opengl.\n\n#### AOT Compilation\n\nWhen AOT (ahead-of-time) compilation is used, Halide generates OpenGL-enabled\nobject files that can be linked to and called from a host application. In\ngeneral, this is fairly straightforward, but a few things must be taken care of.\n\nOn Linux, OS X, and Android, Halide creates its own OpenGL context unless the\ncurrent thread already has an active context. On other platforms you have to\nlink implementations of the following two functions with your Halide code:\n\n```\nextern \"C\" int halide_opengl_create_context(void *) {\n    return 0;  // if successful\n}\n\nextern \"C\" void *halide_opengl_get_proc_addr(void *, const char *name) {\n    ...\n}\n```\n\nHalide allocates and deletes textures as necessary. Applications may manage the\ntextures by hand by setting the `halide_buffer_t::device` field; this is most\nuseful for reusing image data that is already stored in textures. Some\nrudimentary checks are performed to ensure that externally allocated textures\nhave the correct format, but in general that's the responsibility of the\napplication.\n\nIt is possible to let render directly to the current framebuffer; to do this,\nset the `dev` field of the output buffer to the value returned by\n`halide_opengl_output_client_bound`. The example in apps/HelloAndroidGL\ndemonstrates this technique.\n\nSome operating systems can delete the OpenGL context of suspended applications.\nIf this happens, Halide needs to re-initialize itself with the new context after\nthe application resumes. Call `halide_opengl_context_lost` to reset Halide's\nOpenGL state after this has happened.\n\n#### Limitations\n\nThe current implementation of the OpenGL backend targets the common subset of\nOpenGL 2.0 and OpenGL ES 2.0 which is widely available on both mobile devices\nand traditional computers. As a consequence, only a subset of the Halide\nlanguage can be scheduled to run using OpenGL. Some important limitations are:\n\n- Reductions cannot be implemented in GLSL and must be run on the CPU.\n\n- OpenGL ES 2.0 only supports uint8 buffers.\n\n  Support for floating point texture is available, but requires OpenGL (ES) 3.0\n  or the texture_float extension, which may not work on all mobile devices.\n\n- OpenGL ES 2.0 has very limited support for integer arithmetic. For maximum\n  compatibility, consider doing all computations using floating point, even when\n  using integer textures.\n\n- Only 2D images with 3 or 4 color channels can be scheduled. Images with one or\n  two channels require OpenGL (ES) 3.0 or the texture_rg extension.\n\n- Not all builtin functions provided by Halide are currently supported, for\n  example `fast_log`, `fast_exp`, `fast_pow`, `reinterpret`, bit operations,\n  `random_float`, `random_int` cannot be used in GLSL code.\n\nThe maximum texture size in OpenGL is `GL_MAX_TEXTURE_SIZE`, which is often\nsmaller than the image of interest; on mobile devices, for example,\n`GL_MAX_TEXTURE_SIZE` is commonly 2048. Tiling must be used to process larger\nimages.\n\nPlanned features:\n\n- Support for half-float textures and arithmetic\n\n- Support for integer textures and arithmetic\n\n(Note that OpenGL Compute Shaders are supported with a separate OpenGLCompute\nbackend.)\n\n# Halide for Hexagon HVX\n\nHalide supports offloading work to Qualcomm Hexagon DSP on Qualcomm Snapdragon\n835 devices or newer. The Hexagon DSP provides a set of 128 byte vector instruction\nextensions - the Hexagon Vector eXtensions (HVX). HVX is well suited for image\nprocessing, and Halide for Hexagon HVX will generate the appropriate HVX vector\ninstructions from a program authored in Halide.\n\nHalide can be used to compile Hexagon object files directly, by using a target\nsuch as `hexagon-32-qurt-hvx`.\n\nHalide can also be used to offload parts of a pipeline to Hexagon using the\n`hexagon` scheduling directive. To enable the `hexagon` scheduling directive,\ninclude the `hvx` target feature in your target. The currently\nsupported combination of targets is to use the HVX target features with an x86\nlinux host (to use the simulator) or with an ARM android target (to use Hexagon\nDSP hardware). For examples of using the `hexagon` scheduling directive on both\nthe simulator and a Hexagon DSP, see the blur example app.\n\nTo build and run an example app using the Hexagon target,\n\n1. Obtain and build trunk LLVM and Clang. (Earlier versions of LLVM may work but\n   are not actively tested and thus not recommended.)\n2. Download and install the Hexagon SDK and Hexagon Tools. Hexagon SDK 3.4.1 or later\n   is needed. Hexagon Tools 8.2 or later is needed.\n3. Build and run an example for Hexagon HVX\n\n### 1. Obtain and build trunk LLVM and Clang\n\n(Instructions given previous, just be sure to check out the `master` branch.)\n\n### 2. Download and install the Hexagon SDK and Hexagon Tools\n\nGo to https://developer.qualcomm.com/software/hexagon-dsp-sdk/tools\n\n1. Select the Hexagon Series 600 Software and download the 3.4.1 version or later\n   for Linux.\n2. untar the installer\n3. Run the extracted installer to install the Hexagon SDK and Hexagon Tools,\n   selecting Installation of Hexagon SDK into `/location/of/SDK/Hexagon_SDK/3.x`\n   and the Hexagon tools into `/location/of/SDK/Hexagon_Tools/8.x`\n4. Set an environment variable to point to the SDK installation location\n   ```\n   export SDK_LOC=/location/of/SDK\n   ```\n\n### 3. Build and run an example for Hexagon HVX\n\nIn addition to running Hexagon code on device, Halide also supports running\nHexagon code on the simulator from the Hexagon tools.\n\nTo build and run the blur example in Halide/apps/blur on the simulator:\n\n```\ncd apps/blur\nexport HL_HEXAGON_SIM_REMOTE=../../src/runtime/hexagon_remote/bin/v62/hexagon_sim_remote\nexport HL_HEXAGON_TOOLS=$SDK_LOC/Hexagon_Tools/8.x/Tools/\nLD_LIBRARY_PATH=../../src/runtime/hexagon_remote/bin/host/:$HL_HEXAGON_TOOLS/lib/iss/:. HL_TARGET=host-hvx make test\n```\n\n### To build and run the blur example in Halide/apps/blur on Android:\n\nTo build the example for Android, first ensure that you have Android NDK r19b or\nlater installed, and the ANDROID_NDK_ROOT environment variable points to it.\n(Note that Qualcomm Hexagon SDK v3.5.2 includes Android NDK r19c, which is fine.)\n\nNow build and run the blur example using the script to run it on device:\n\n```\nexport HL_HEXAGON_TOOLS=$SDK_LOC/HEXAGON_Tools/8.0/Tools/\nHL_TARGET=arm-64-android-hvx ./adb_run_on_device.sh\n```\n"
}