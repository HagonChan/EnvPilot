{
    "primary_language": "C",
    "language_guidelines": "# General Guidelines : \n**General Guidelines for C/C++ Projects**\n\n1. **Read the README**  \n   Start by reading the project's README file on GitHub. It contains important instructions for installation, usage, and project-specific details.  \n\n2. **Check Dependencies**  \n   Look for dependencies listed in the README or package management files like `CMakeLists.txt` (for CMake), `Makefile` (for Make), or `vcpkg.json` (for vcpkg). Ensure the required compiler and libraries are installed.  \n\n3. **Build Tool**  \n   Identify the build tool the project is using: Make, CMake, or another. This information should be available in the README or through project configuration files (e.g., `Makefile` for Make, `CMakeLists.txt` for CMake).  \n\n4. **Build the Project**  \n   Depending on the build tool, use the appropriate commands to build the project:  \n\n   - For Make:  \n     ```  \n     make  \n     ```  \n   - For CMake:  \n     ```  \n     mkdir build  \n     cd build  \n     cmake ..  \n     make  \n     ```  \n\n5. **Configuration**  \n   Check if the project requires configuration files (e.g., `.conf` files, `config.h` headers) to be set up. This may involve providing paths to dependencies or setting compilation flags.  \n\n6. **Run Tests (if available)**  \n   If the project provides tests, it's a good idea to run them to ensure everything is working correctly. Common testing frameworks for C/C++ include Google Test (gtest), Catch2, and Boost.Test.  \n   - For Google Test:  \n     ```  \n     ./path/to/test_executable  \n     ```  \n   - For Catch2:  \n     ```  \n     ./path/to/test_executable  \n     ```  \n\n7. **Run the Project**  \n   Follow the instructions in the README to run the project. This could involve running a specific executable, starting a server, or executing a specific command.  \n\n8. **Troubleshooting**  \n   If you encounter issues during installation or while running the project, refer to the project's issue tracker on GitHub or search for similar issues.  \n\n9. **Documentation**  \n   Review additional documentation such as Doxygen files, API documentation, or inline comments in the code. Understanding the documentation provides better insights into the project\u2019s structure and usage.",
    "workflow_guidelines": "\nThe following workflow files might contain information on how to set up the project and run test cases.  This might be useful later on when building/installing and testing the project:\n\nfile: integration-build-master.yaml\nContent:\nname: Build master docker images for integration tests\non:\n  push:\n    branches:\n      - master\njobs:\n  docker_build:\n    strategy:\n      max-parallel: 3\n      fail-fast: false\n      matrix:\n        tag: [ 'master', 'master_debug' ]\n    runs-on: ubuntu-latest\n    steps:\n      - name: Setup environment\n        run: |\n          sudo apt-get --yes update\n          sudo apt-get install --yes docker.io containerd runc\n          sudo systemctl unmask docker && sudo systemctl start docker\n\n      - uses: actions/checkout@v2\n      - name: Build a docker image for master branch\n        run: |\n          DOCKER_BUILDKIT=1 docker build --no-cache -f ./dockerfiles/Dockerfile.${{ env.arch }}-${{ matrix.tag }} -t ${{ env.dockerhub_organization }}/fluent-bit:${{ env.arch }}-${{ matrix.tag }} .\n        env:\n          arch: x86_64\n          dockerhub_organization: fluentbitdev\n\n      - name: Archive the docker images\n        uses: ishworkh/docker-image-artifact-upload@v1\n        with:\n          image: ${{ env.dockerhub_organization }}/fluent-bit:${{ env.arch }}-${{ matrix.tag }}\n        env:\n          arch: x86_64\n          dockerhub_organization: fluentbitdev\n\nfile: build-release.yaml\nContent:\non:\n  push:\n    tags:\n      - '*'\n  release:\n    types: [created]\nname: Build release\njobs:\n  build-distro-packages:\n    name: build packages\n    strategy:\n      max-parallel: 48\n      fail-fast: true\n      matrix:\n        distro: [ amazonlinux/2, amazonlinux/2.arm64v8, centos/7, centos/7.arm64v8, debian/jessie,\n                  debian/jessie.arm64v8, debian/stretch, debian/stretch.arm64v8, debian/buster,\n                  debian/buster.arm64v8, ubuntu/16.04, ubuntu/18.04, ubuntu/20.04, ubuntu/18.04.arm64v8,\n                  ubuntu/20.04.arm64v8, raspbian/jessie, raspbian/stretch, raspbian/buster ]\n\n    runs-on: [ ubuntu-latest ] #self-hosted, Linux, X64, packet-builder]\n    steps:\n      - name: Setup environment\n        run: |\n            sudo apt-get install --yes qemu binfmt-support qemu-user-static qemu-utils qemu-efi-aarch64 qemu-system-arm docker.io containerd runc\n            sudo systemctl unmask docker && sudo systemctl start docker\n            docker run --rm --privileged --name qemu multiarch/qemu-user-static:register --reset\n\n      - name: Get the version\n        id: get_version\n        run: echo ::set-output name=VERSION::${GITHUB_REF/refs\\/tags\\//}\n\n      - uses: frabert/replace-string-action@master\n        id: formatted_version\n        with:\n          pattern: '[v]*(.*)$'\n          string: \"${{ steps.get_version.outputs.VERSION }}\"\n          replace-with: '$1'\n          flags: 'g'\n\n      - uses: frabert/replace-string-action@master\n        id: formatted_distro\n        with:\n          pattern: '(.*)\\/(.*)$'\n          string: \"${{ matrix.distro }}\"\n          replace-with: '$1-$2'\n          flags: 'g'\n\n      - uses: actions/checkout@v2\n        with:\n          repository: ${{ github.actor }}/fluent-bit-packaging\n          fetch-depth: 1\n          path: packaging\n\n      - name: Build the distro artifacts\n        run: ./build.sh -v ${{ env.release }} -d ${{ env.distro }}\n        env:\n          release: ${{ steps.formatted_version.outputs.replaced }}\n          distro: ${{ matrix.distro }}\n        working-directory: packaging\n\n      - name: Archive the release artifacts (packages)\n        uses: actions/upload-artifact@v2\n        with:\n          name: release-${{env.release}}-${{env.bucket-name}}-pkgs\n          path: |\n            packaging/packages/${{env.distro}}/${{env.release}}/**/*\n        env:\n          bucket-name: ${{ steps.formatted_distro.outputs.replaced }}\n          release: ${{ steps.formatted_version.outputs.replaced }}\n          distro: ${{ matrix.distro }}\n\n  build-docker-images:\n    name: build docker images\n    strategy:\n      max-parallel: 48\n      fail-fast: true\n      matrix:\n        arch: [ amd64, arm64v8, arm32v7 ]\n        suffix: [ x86_64, arm64v8, arm32v7, x86_64-debug ]\n        os: [ linux ]\n        exclude:\n          - {arch: amd64, suffix: arm64v8}\n          - {arch: amd64, suffix: arm32v7}\n          - {arch: arm64v8, suffix: x86_64}\n          - {arch: arm64v8, suffix: arm32v7}\n          - {arch: arm64v8, suffix: x86_64-debug}\n          - {arch: arm32v7, suffix: x86_64}\n          - {arch: arm32v7, suffix: arm64v8}\n          - {arch: arm32v7, suffix: x86_64-debug}\n    runs-on: [ ubuntu-latest ] #self-hosted, Linux, X64, packet-builder]\n    steps:\n      - uses: actions/checkout@master\n      - name: Setup environment\n        run: |\n          sudo apt-get install --yes qemu binfmt-support qemu-user-static qemu-utils qemu-efi-aarch64 qemu-system-arm docker.io containerd runc\n          sudo systemctl unmask docker && sudo systemctl start docker\n          docker run --rm --privileged --name qemu multiarch/qemu-user-static:register --reset\n\n      - name: Get the version\n        id: get_version\n        run: echo ::set-output name=VERSION::${GITHUB_REF/refs\\/tags\\//}\n\n      - uses: frabert/replace-string-action@master\n        id: formatted_version\n        with:\n          pattern: '[v]*(.*)$'\n          string: \"${{ steps.get_version.outputs.VERSION }}\"\n          replace-with: '$1'\n          flags: 'g'\n\n      - name: Build the docker images\n        run: docker buildx build --no-cache -f ./dockerfiles/Dockerfile.${{ env.suffix }} -t ${{ env.dockerhub_organization }}/fluent-bit:${{ env.suffix }}-${{ env.release }} --platform ${{ env.os }}/${{ env.arch }} .\n        env:\n          release: ${{ steps.formatted_version.outputs.replaced }}\n          arch: ${{ matrix.arch }}\n          suffix: ${{ matrix.suffix }}\n          os: ${{ matrix.os }}\n          dockerhub_organization: ${{ secrets.DOCKERHUB_ORGANIZATION }}\n\n      - name: Archive the docker images\n        uses: ishworkh/docker-image-artifact-upload@v1\n        with:\n          image: ${{ env.dockerhub_organization }}/fluent-bit:${{ env.arch }}-${{ env.release }}\n        env:\n          release: ${{ steps.formatted_version.outputs.replaced }}\n          arch: ${{ matrix.arch }}\n          dockerhub_organization: ${{ secrets.DOCKERHUB_ORGANIZATION }}\n\nfile: build-master-packages.yaml\nContent:\non:\n  push:\n    branches:\n      - master\n\nname: Build packages for master\njobs:\n  build-distro-packages:\n    name: build packages\n    strategy:\n      max-parallel: 48\n      fail-fast: true\n      matrix:\n        distro: [ ubuntu/16.04, ubuntu/18.04, ubuntu/20.04, debian/buster ]\n\n    runs-on: [ ubuntu-latest ] #self-hosted, Linux, X64, packet-builder]\n    steps:\n      - name: Setup environment\n        run: |\n          sudo apt-get update\n          sudo apt-get install --yes qemu binfmt-support qemu-user-static qemu-utils qemu-efi-aarch64 qemu-system-arm docker.io containerd runc\n          sudo systemctl unmask docker && sudo systemctl start docker\n          docker run --rm --privileged --name qemu multiarch/qemu-user-static:register --reset\n\n      - uses: frabert/replace-string-action@master\n        id: formatted_distro\n        with:\n          pattern: '(.*)\\/(.*)$'\n          string: \"${{ matrix.distro }}\"\n          replace-with: '$1-$2'\n          flags: 'g'\n\n      - uses: actions/checkout@v2\n        with:\n          repository: fluent/fluent-bit-packaging\n          fetch-depth: 1\n          path: packaging\n\n      - name: Build the distro artifacts\n        run: ./build.sh -v master -d ${{ env.distro }} -b master\n        env:\n          distro: ${{ matrix.distro }}\n        working-directory: packaging\n\n      - name: Store the master package artifacts\n        uses: actions/upload-artifact@v2\n        with:\n          name: packages-${{env.release}}-${{env.bucket-name}}\n          path: |\n            packaging/packages/${{env.distro}}/${{env.release}}/**/*\n        env:\n          bucket-name: ${{ steps.formatted_distro.outputs.replaced }}\n          release: master\n          distro: ${{ matrix.distro }}\n",
    "readme": "# ![logo](fluentbit_logo.png)\n\n### CI Status\n\n| CI Workflow       | Status             |\n|-------------------|--------------------|\n| Unit Tests (master) | [![CI/Unit Tests](https://github.com/fluent/fluent-bit/actions/workflows/unit-tests.yaml/badge.svg?branch=master)](https://github.com/fluent/fluent-bit/actions/workflows/unit-tests.yaml) |\n| Integration Tests (master) | [![CI/Integration Tests](https://github.com/fluent/fluent-bit/actions/workflows/integration-run-master.yaml/badge.svg)](https://github.com/fluent/fluent-bit/actions/workflows/integration-run-master.yaml)|\n| Docker images (master) | [![CI/Docker Images](https://github.com/fluent/fluent-bit/actions/workflows/integration-build-master.yaml/badge.svg)](https://github.com/fluent/fluent-bit/actions/workflows/integration-build-master.yaml)|\n| Latest release build |  [![CI/Build](https://github.com/fluent/fluent-bit/actions/workflows/build-release.yaml/badge.svg)](https://github.com/fluent/fluent-bit/actions/workflows/build-release.yaml)|\n\n\n## Project Description\n\n[Fluent Bit](http://fluentbit.io) is a fast Log Processor and Forwarder for Linux, Windows, Embedded Linux, MacOS and BSD family operating systems. It's part of the Graduated [Fluentd](http://fluentd.org) Ecosystem and a [CNCF](https://cncf.io) sub-project.\n\nFluent Bit allows to collect log events or metrics from different sources, process them and deliver them to different backends such as [Fluentd](http://fluentd.org), Elasticsearch, Splunk, DataDog, Kafka, New Relic, Azure services, AWS services, Google services, NATS, InfluxDB or any custom HTTP end-point.\n\nFluent Bit comes with full SQL [Stream Processing](https://docs.fluentbit.io/manual/stream-processing/introduction) capabilities: data manipulation and analytics using SQL queries.\n\nFluent Bit runs on x86_64, x86, arm32v7 and arm64v8 architectures.\n\n## Features\n\n- High Performance\n- Data Parsing\n  - Convert your unstructured messages using our parsers: [JSON](https://docs.fluentbit.io/manual/pipeline/parsers/json), [Regex](https://docs.fluentbit.io/manual/pipeline/parsers/regular-expression), [LTSV](https://docs.fluentbit.io/manual/pipeline/parsers/ltsv) and [Logfmt](https://docs.fluentbit.io/manual/pipeline/parsers/logfmt)\n- Reliability and Data Integrity\n  - [Backpressure](https://docs.fluentbit.io/manual/administration/backpressure) Handling\n  - [Data Buffering](https://docs.fluentbit.io/manual/administration/buffering-and-storage) in memory and file system\n- Networking\n  - Security: built-in TLS/SSL support\n  - Asynchronous I/O\n- Pluggable Architecture and [Extensibility](https://docs.fluentbit.io/manual/development): Inputs, Filters and Outputs\n  - More than 70 built-in plugins available\n  - Extensibility\n    - Write any input, filter or output plugin in C language\n    - Write [Filters in Lua](https://docs.fluentbit.io/manual/filter/lua) or [Output plugins in Golang](https://docs.fluentbit.io/manual/development/golang-output-plugins)\n- [Monitoring](https://docs.fluentbit.io/manual/administration/monitoring): expose internal metrics over HTTP in JSON and [Prometheus](https://prometheus.io/) format\n- [Stream Processing](https://docs.fluentbit.io/manual/stream-processing/introduction): Perform data selection and transformation using simple SQL queries\n  - Create new streams of data using query results\n  - Aggregation Windows\n  - Data analysis and prediction: Timeseries forecasting\n- Portable: runs on Linux, MacOS, Windows and BSD systems\n\n## Fluent Bit in Production\n\n[Fluent Bit](https://fluentbit.io) is used widely in production environments. In 2020 Fluent Bit was deployed more than **220 Million** times, and continues to be deploy over **1 million times a day**. The following is a preview of who uses Fluent Bit heavily in production:\n\n> If your company uses Fluent Bit and is not listed, feel free to open a Github issue and we will add the logo.\n\n![users](documentation/fluentbit_users.png)\n\n## [Documentation](https://docs.fluentbit.io)\n\nOur official project documentation for [installation](https://docs.fluentbit.io/manual/installation), [configuration](https://docs.fluentbit.io/manual/administration/configuring-fluent-bit), deployment and development topics is located here:\n\n- [https://docs.fluentbit.io](https://fluentbit.io)\n\n### Quick Start\n\n#### Build from Scratch\n\nIf you aim to build Fluent Bit from sources, you can go ahead and start with the following commands.\n\n```bash\ncd build\ncmake ..\nmake\nbin/fluent-bit -i cpu -o stdout -f 1\n```\n\nIf you are interested into more details, please refer to the [Build & Install](https://docs.fluentbit.io/manual/installation/sources/build-and-install) section.\n\n#### Linux Packages\n\nWe provide packages for most common Linux distributions:\n\n- [Debian](https://docs.fluentbit.io/manual/installation/linux/debian)\n- [Raspbian](https://docs.fluentbit.io/manual/installation/linux/raspbian-raspberry-pi)\n- [Ubuntu](https://docs.fluentbit.io/manual/installation/linux/ubuntu)\n- [CentOS](https://docs.fluentbit.io/manual/installation/linux/redhat-centos)\n\n#### Linux / Docker Container Images\n\nOur Linux containers images are the most common deployment model, thousands of\nnew installation happen every day, learn more about the available images and\ntags [here](https://docs.fluentbit.io/manual/installation/docker).\n\n#### Windows Packages\n\nFluent Bit is fully supported on Windows environments, get started with [these instructions](https://docs.fluentbit.io/manual/installation/windows).\n\n### Plugins: Inputs, Filters and Outputs\n\n[Fluent Bit](http://fluentbit.io) is based in a pluggable architecture where different plugins plays a major role in the data pipeline:\n\n#### Input Plugins\n\n| name | title | description |\n| :--- | :--- | :--- |\n| [collectd](https://docs.fluentbit.io/manual/pipeline/inputs/collectd) | Collectd | Listen for UDP packets from Collectd. |\n| [cpu](https://docs.fluentbit.io/manual/pipeline/inputs/cpu-metrics) | CPU Usage | measure total CPU usage of the system. |\n| [disk](https://docs.fluentbit.io/manual/pipeline/inputs/disk-io-metrics) | Disk Usage | measure Disk I/Os. |\n| [dummy](https://docs.fluentbit.io/manual/pipeline/inputs/dummy) | Dummy | generate dummy event. |\n| [exec](https://docs.fluentbit.io/manual/pipeline/inputs/exec) | Exec | executes external program and collects event logs. |\n| [forward](https://docs.fluentbit.io/manual/pipeline/inputs/forward) | Forward | Fluentd forward protocol. |\n| [head](https://docs.fluentbit.io/manual/pipeline/inputs/head) | Head | read first part of files. |\n| [health](https://docs.fluentbit.io/manual/pipeline/inputs/health) | Health | Check health of TCP services. |\n| [kmsg](https://docs.fluentbit.io/manual/pipeline/inputs/kernel-logs) | Kernel Log Buffer | read the Linux Kernel log buffer messages. |\n| [mem](https://docs.fluentbit.io/manual/pipeline/inputs/memory-metrics) | Memory Usage | measure the total amount of memory used on the system. |\n| [mqtt](https://docs.fluentbit.io/manual/pipeline/inputs/mqtt) | MQTT | start a MQTT server and receive publish messages. |\n| [netif](https://docs.fluentbit.io/manual/pipeline/inputs/network-io-metrics) | Network Traffic | measure network traffic. |\n| [proc](https://docs.fluentbit.io/manual/pipeline/inputs/process) | Process | Check health of Process. |\n| [random](https://docs.fluentbit.io/manual/pipeline/inputs/random) | Random | Generate Random samples. |\n| [serial](https://docs.fluentbit.io/manual/pipeline/inputs/serial-interface) | Serial Interface | read data information from the serial interface. |\n| [stdin](https://docs.fluentbit.io/manual/pipeline/inputs/standard-input) | Standard Input | read data from the standard input. |\n| [syslog](https://docs.fluentbit.io/manual/pipeline/inputs/syslog) | Syslog | read syslog messages from a Unix socket. |\n| [systemd](https://docs.fluentbit.io/manual/pipeline/inputs/systemd) | Systemd | read logs from Systemd/Journald. |\n| [tail](https://docs.fluentbit.io/manual/pipeline/inputs/tail) | Tail | Tail log files. |\n| [tcp](https://docs.fluentbit.io/manual/pipeline/inputs/tcp) | TCP | Listen for JSON messages over TCP. |\n| [thermal](https://docs.fluentbit.io/manual/pipeline/inputs/thermal) | Thermal | measure system temperature(s). |\n\n#### Filter Plugins\n\n| name | title | description |\n| :--- | :--- | :--- |\n| [aws](https://docs.fluentbit.io/manual/pipeline/filters/aws-metadata) | AWS Metadata | Enrich logs with AWS Metadata. |\n| [expect](https://docs.fluentbit.io/manual/pipeline/filters/expect) | Expect | Validate records match certain criteria in structure. |\n| [grep](https://docs.fluentbit.io/manual/pipeline/filters/grep) | Grep | Match or exclude specific records by patterns. |\n| [kubernetes](https://docs.fluentbit.io/manual/pipeline/filters/kubernetes) | Kubernetes | Enrich logs with Kubernetes Metadata. |\n| [lua](https://docs.fluentbit.io/manual/pipeline/filters/lua) | Lua | Filter records using Lua Scripts. |\n| [parser](https://docs.fluentbit.io/manual/pipeline/filters/parser) | Parser | Parse record. |\n| [record\\_modifier](https://docs.fluentbit.io/manual/pipeline/filters/record-modifier) | Record Modifier | Modify record. |\n| [rewrite\\_tag](https://docs.fluentbit.io/manual/pipeline/filters/rewrite-tag) | Rewrite Tag | Re-emit records under new tag. |\n| [stdout](https://docs.fluentbit.io/manual/pipeline/filters/standard-output) | Stdout | Print records to the standard output interface. |\n| [throttle](https://docs.fluentbit.io/manual/pipeline/filters/throttle) | Throttle | Apply rate limit to event flow. |\n| [nest](https://docs.fluentbit.io/manual/pipeline/filters/nest) | Nest | Nest records under a specified key |\n| [modify](https://docs.fluentbit.io/manual/pipeline/filters/modify) | Modify | Modifications to record. |\n\n#### Output Plugins\n\n| name | title | description |\n| :--- | :--- | :--- |\n| [azure](https://docs.fluentbit.io/manual/pipeline/outputs/azure) | Azure Log Analytics | Ingest records into Azure Log Analytics |\n| [bigquery](https://docs.fluentbit.io/manual/pipeline/outputs/bigquery) | BigQuery | Ingest records into Google BigQuery |\n| [counter](https://docs.fluentbit.io/manual/pipeline/outputs/counter) | Count Records | Simple records counter. |\n| [datadog](https://docs.fluentbit.io/manual/pipeline/outputs/datadog) | Datadog | Ingest logs into Datadog. |\n| [es](https://docs.fluentbit.io/manual/pipeline/outputs/elasticsearch) | Elasticsearch | flush records to a Elasticsearch server. |\n| [file](https://docs.fluentbit.io/manual/pipeline/outputs/file) | File | Flush records to a file. |\n| [flowcounter](https://docs.fluentbit.io/manual/pipeline/outputs/flowcounter) | FlowCounter | Count records. |\n| [forward](https://docs.fluentbit.io/manual/pipeline/outputs/forward) | Forward | Fluentd forward protocol. |\n| [gelf](https://docs.fluentbit.io/manual/pipeline/outputs/gelf) | GELF | Flush records to Graylog |\n| [http](https://docs.fluentbit.io/manual/pipeline/outputs/http) | HTTP | Flush records to an HTTP end point. |\n| [influxdb](https://docs.fluentbit.io/manual/pipeline/outputs/influxdb) | InfluxDB | Flush records to InfluxDB time series database. |\n| [kafka](https://docs.fluentbit.io/manual/pipeline/outputs/kafka) | Apache Kafka | Flush records to Apache Kafka |\n| [kafka-rest](https://docs.fluentbit.io/manual/pipeline/outputs/kafka-rest-proxy) | Kafka REST Proxy | Flush records to a Kafka REST Proxy server. |\n| [nats](https://docs.fluentbit.io/manual/pipeline/outputs/nats) | NATS | Flush records to a NATS server. |\n| [null](https://docs.fluentbit.io/manual/pipeline/outputs/null) | NULL | Throw away events. |\n| [s3](https://docs.fluentbit.io/manual/pipeline/outputs/s3) | S3 | Flush records to s3 |\n| [stackdriver](https://docs.fluentbit.io/manual/pipeline/outputs/stackdriver) | Google Stackdriver Logging | Flush records to Google Stackdriver Logging service. |\n| [stdout](https://docs.fluentbit.io/manual/pipeline/outputs/standard-output) | Standard Output | Flush records to the standard output. |\n| [splunk](https://docs.fluentbit.io/manual/pipeline/outputs/splunk) | Splunk | Flush records to a Splunk Enterprise service |\n| [tcp](https://docs.fluentbit.io/manual/pipeline/outputs/tcp-and-tls) | TCP & TLS | Flush records to a TCP server. |\n| [td](https://docs.fluentbit.io/manual/pipeline/outputs/treasure-data) | [Treasure Data](http://www.treasuredata.com) | Flush records to the [Treasure Data](http://www.treasuredata.com) cloud service for analytics. |\n\n## Contributing\n\n[Fluent Bit](https://fluentbit.io) is an open project, several individuals and companies contribute in different forms like coding, documenting, testing, spreading the word at events within others. If you want to learn more about contributing opportunities please reach out to us through our [Community Channels](https://fluentbit.io/community/).\n\nIf you are interested in contributing to Fluent bit with bug fixes, new features or coding in general, please refer to the code [CONTRIBUTING](CONTRIBUTING.md) guidelines. You can also refer the Beginners Guide to contributing to Fluent Bit [here.](DEVELOPER_GUIDE.md)\n\n## Community & Contact\n\nFeel free to join us on our Slack channel, Mailing List or IRC:\n\n- [Slack](http://slack.fluentd.org) (#fluent-bit channel)\n- [Mailing List](https://groups.google.com/forum/#!forum/fluent-bit)\n- [Discourse Forum](https://discuss.fluentd.org)\n- [Twitter](http://twitter.com/fluentbit)\n- [IRC](irc.freenode.net) #fluent-bit\n\n## License\n\nThis program is under the terms of the [Apache License v2.0](http://www.apache.org/licenses/LICENSE-2.0).\n\n## Authors\n\n[Fluent Bit](http://fluentbit.io) is originally made and currently sponsored by [Treasure Data](http://treasuredata.com) among other [contributors](https://github.com/fluent/fluent-bit/graphs/contributors).\n",
    "org": "fluent",
    "repo": "fluent-bit",
    "number": 3663,
    "commit": "b0f0b290375ecac2e3b1979ffb4b42331d58367a"
}