{
    "primary_language": "C",
    "language_guidelines": "# General Guidelines : \n**General Guidelines for C/C++ Projects**\n\n1. **Read the README**  \n   Start by reading the project's README file on GitHub. It contains important instructions for installation, usage, and project-specific details.  \n\n2. **Check Dependencies**  \n   Look for dependencies listed in the README or package management files like `CMakeLists.txt` (for CMake), `Makefile` (for Make), or `vcpkg.json` (for vcpkg). Ensure the required compiler and libraries are installed.  \n\n3. **Build Tool**  \n   Identify the build tool the project is using: Make, CMake, or another. This information should be available in the README or through project configuration files (e.g., `Makefile` for Make, `CMakeLists.txt` for CMake).  \n\n4. **Build the Project**  \n   Depending on the build tool, use the appropriate commands to build the project:  \n\n   - For Make:  \n     ```  \n     make  \n     ```  \n   - For CMake:  \n     ```  \n     mkdir build  \n     cd build  \n     cmake ..  \n     make  \n     ```  \n\n5. **Configuration**  \n   Check if the project requires configuration files (e.g., `.conf` files, `config.h` headers) to be set up. This may involve providing paths to dependencies or setting compilation flags.  \n\n6. **Run Tests (if available)**  \n   If the project provides tests, it's a good idea to run them to ensure everything is working correctly. Common testing frameworks for C/C++ include Google Test (gtest), Catch2, and Boost.Test.  \n   - For Google Test:  \n     ```  \n     ./path/to/test_executable  \n     ```  \n   - For Catch2:  \n     ```  \n     ./path/to/test_executable  \n     ```  \n\n7. **Run the Project**  \n   Follow the instructions in the README to run the project. This could involve running a specific executable, starting a server, or executing a specific command.  \n\n8. **Troubleshooting**  \n   If you encounter issues during installation or while running the project, refer to the project's issue tracker on GitHub or search for similar issues.  \n\n9. **Documentation**  \n   Review additional documentation such as Doxygen files, API documentation, or inline comments in the code. Understanding the documentation provides better insights into the project\u2019s structure and usage.",
    "workflow_guidelines": "\nThe following workflow files might contain information on how to set up the project and run test cases.  This might be useful later on when building/installing and testing the project:\n\nfile: build-legacy-branch.yaml\nContent:\nname: Build containers for a specific branch of 1.8\non:\n  workflow_dispatch:\n    inputs:\n      ref:\n        description: The code to build so a commit, branch, etc. The container image will be ghcr.io/fluent/fluent-bit/test/<this value>.\n        required: true\n        default: \"1.8\"\n\nenv:\n  IMAGE_NAME: ghcr.io/${{ github.repository }}/test/${{ github.event.inputs.ref }}\n\njobs:\n  build-legacy-branch-meta:\n    runs-on: ubuntu-latest\n    permissions:\n      contents: read\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n        with:\n          ref: ${{ inputs.ref }}\n\n      - name: Check this is a 1.8 type build\n        run: |\n          if [[ -f \"dockerfiles/Dockerfile\" ]]; then\n            echo \"Invalid branch as contains Dockerfile: ${{ inputs.ref }}\"\n            exit 1\n          fi\n        shell: bash\n\n  # For 1.8 builds it is a little more complex so we have this build matrix to handle it.\n  # This creates separate images for each architecture.\n  # The later step then creates a multi-arch manifest for all of these.\n  build-legacy-images-matrix:\n    name: Build single arch legacy images\n    runs-on: ubuntu-latest\n    needs:\n      - build-legacy-branch-meta\n    strategy:\n      fail-fast: false\n      matrix:\n        arch: [amd64, arm64, arm/v7]\n        include:\n          - arch: amd64\n            suffix: x86_64\n          - arch: arm/v7\n            suffix: arm32v7\n          - arch: arm64\n            suffix: arm64v8\n    permissions:\n      contents: read\n      packages: write\n    steps:\n      - name: Checkout the docker build repo for legacy builds\n        uses: actions/checkout@v4\n        with:\n          repository: fluent/fluent-bit-docker-image\n          ref: \"1.8\" # Fixed to this branch\n\n      - name: Set up QEMU\n        uses: docker/setup-qemu-action@v3\n\n      - name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v3\n\n      - name: Log in to the Container registry\n        uses: docker/login-action@v3\n        with:\n          registry: ghcr.io\n          username: ${{ github.actor }}\n          password: ${{ secrets.GITHUB_TOKEN }}\n\n      - id: debug-meta\n        uses: docker/metadata-action@v5\n        with:\n          images: ${{ env.IMAGE_NAME }}\n          tags: |\n            raw,${{ inputs.ref }}-debug\n\n      - name: Build the legacy x86_64 debug image\n        if: matrix.arch == 'amd64'\n        uses: docker/build-push-action@v6\n        with:\n          file: ./Dockerfile.x86_64.debug\n          context: .\n          tags: ${{ steps.debug-meta.outputs.tags }}\n          labels: ${{ steps.debug-meta.outputs.labels }}\n          provenance: false\n          platforms: linux/amd64\n          push: true\n          load: false\n          build-args: |\n            FLB_TARBALL=https://github.com/fluent/fluent-bit/tarball/${{ inputs.ref }}\n\n      - name: Extract metadata from Github\n        id: meta\n        uses: docker/metadata-action@v5\n        with:\n          images: ${{ env.IMAGE_NAME }}\n          tags: |\n            raw,${{ matrix.suffix }}-${{ inputs.ref }}\n\n      - name: Build the legacy ${{ matrix.arch }} image\n        uses: docker/build-push-action@v6\n        with:\n          file: ./Dockerfile.${{ matrix.suffix }}\n          context: .\n          tags: ${{ steps.meta.outputs.tags }}\n          labels: ${{ steps.meta.outputs.labels }}\n          platforms: linux/${{ matrix.arch }}\n          provenance: false\n          push: true\n          load: false\n          build-args: |\n            FLB_TARBALL=https://github.com/fluent/fluent-bit/tarball/${{ inputs.ref }}\n\n  # Create a multi-arch manifest for the separate 1.8 images.\n  build-legacy-image-manifests:\n    name: Deploy multi-arch container image manifests\n    permissions:\n      contents: read\n      packages: write\n    runs-on: ubuntu-latest\n    needs:\n      - build-legacy-branch-meta\n      - build-legacy-images-matrix\n    steps:\n      - name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v3\n\n      - name: Log in to the Container registry\n        uses: docker/login-action@v3\n        with:\n          registry: ghcr.io\n          username: ${{ github.actor }}\n          password: ${{ secrets.GITHUB_TOKEN }}\n\n      - name: Pull all the images\n        # Use platform to trigger warnings on invalid image metadata\n        run: |\n          docker pull --platform=linux/amd64  ${{ env.IMAGE_NAME }}:x86_64-${{ inputs.ref }}\n          docker pull --platform=linux/arm64  ${{ env.IMAGE_NAME }}:arm64v8-${{ inputs.ref }}\n          docker pull --platform=linux/arm/v7 ${{ env.IMAGE_NAME }}:arm32v7-${{ inputs.ref }}\n        shell: bash\n\n      - name: Create manifests for images\n        run: |\n          docker manifest create ${{ env.IMAGE_NAME }}:${{ inputs.ref }} \\\n            --amend ${{ env.IMAGE_NAME }}:x86_64-${{ inputs.ref }} \\\n            --amend ${{ env.IMAGE_NAME }}:arm64v8-${{ inputs.ref }} \\\n            --amend ${{ env.IMAGE_NAME }}:arm32v7-${{ inputs.ref }}\n          docker manifest push --purge ${{ env.IMAGE_NAME }}:${{ inputs.ref }}\n        env:\n          DOCKER_CLI_EXPERIMENTAL: enabled\n        shell: bash\n\nfile: build-branch-containers.yaml\nContent:\nname: Build containers for a specific branch of 1.9+\non:\n  workflow_dispatch:\n    inputs:\n      version:\n        description: Version of Fluent Bit to build, commit, branch, etc. The container image will be ghcr.io/fluent/fluent-bit/test/<this value>.\n        required: true\n        default: master\njobs:\n  build-branch-containers:\n    uses: ./.github/workflows/call-build-images.yaml\n    with:\n      version: ${{ github.event.inputs.version }}\n      ref: ${{ github.event.inputs.version }}\n      registry: ghcr.io\n      username: ${{ github.actor }}\n      image: ${{ github.repository }}/test/${{ github.event.inputs.version }}\n      unstable: ${{ github.event.inputs.version }}\n    secrets:\n      token: ${{ secrets.GITHUB_TOKEN }}\n",
    "readme": "# ![logo](fluentbit_logo.png)\n\n### CI Status\n\n| CI Workflow       | Status             |\n|-------------------|--------------------|\n| Unit Tests (master) | [![CI/Unit Tests](https://github.com/fluent/fluent-bit/actions/workflows/unit-tests.yaml/badge.svg?branch=master)](https://github.com/fluent/fluent-bit/actions/workflows/unit-tests.yaml) |\n| Integration Tests (master) | [![CI/Integration Tests](https://github.com/fluent/fluent-bit/actions/workflows/master-integration-test.yaml/badge.svg)](https://github.com/fluent/fluent-bit/actions/workflows/master-integration-test.yaml)|\n| Arm builds         | <a href=\"https://actuated.dev/\"><img alt=\"Arm CI sponsored by Actuated\" src=\"https://docs.actuated.dev/images/actuated-badge.png\" width=\"120px\"></img></a> |\n| Latest release |  [![CI/Build](https://github.com/fluent/fluent-bit/actions/workflows/staging-release.yaml/badge.svg)](https://github.com/fluent/fluent-bit/actions/workflows/staging-release.yaml)|\n\n## About\n\n![](documentation/fluentbit_ecosystem.png)\n\n[Fluent Bit](http://fluentbit.io) is a fast Log, Metrics and Traces Processor and Forwarder for Linux, Windows, Embedded Linux, MacOS and BSD family operating systems. It's part of the Graduated [Fluentd](http://fluentd.org) Ecosystem and a [CNCF](https://cncf.io) sub-project.\n\nFluent Bit allows to collect different signal types such as logs, metrics and traces from different sources, process them and deliver them to different backends such as [Fluentd](http://fluentd.org), Elasticsearch, Splunk, DataDog, Kafka, New Relic, Azure services, AWS services, Google services, NATS, InfluxDB or any custom HTTP end-point.\n\nFluent Bit comes with full SQL [Stream Processing](https://docs.fluentbit.io/manual/stream-processing/introduction) capabilities: data manipulation and analytics using SQL queries.\n\nFluent Bit runs on x86_64, x86, arm32v7, and arm64v8 architectures.\n\n## Features\n\n- High Performance at low CPU and Memory footprint\n- Data Parsing\n  - Convert your unstructured messages using our parsers: [JSON](https://docs.fluentbit.io/manual/pipeline/parsers/json), [Regex](https://docs.fluentbit.io/manual/pipeline/parsers/regular-expression), [LTSV](https://docs.fluentbit.io/manual/pipeline/parsers/ltsv) and [Logfmt](https://docs.fluentbit.io/manual/pipeline/parsers/logfmt)\n- Reliability and Data Integrity\n  - [Backpressure](https://docs.fluentbit.io/manual/administration/backpressure) Handling\n  - [Data Buffering](https://docs.fluentbit.io/manual/administration/buffering-and-storage) in memory and file system\n- Networking\n  - Security: built-in TLS/SSL support\n  - Asynchronous I/O\n- Pluggable Architecture and [Extensibility](https://docs.fluentbit.io/manual/development): Inputs, Filters and Outputs\n  - More than 70 built-in plugins available\n  - Extensibility\n    - Write any input, filter or output plugin in C language\n    - Write [Filters in Lua](https://docs.fluentbit.io/manual/filter/lua) or [Output plugins in Golang](https://docs.fluentbit.io/manual/development/golang-output-plugins)\n- [Monitoring](https://docs.fluentbit.io/manual/administration/monitoring): expose internal metrics over HTTP in JSON and [Prometheus](https://prometheus.io/) format\n- [Stream Processing](https://docs.fluentbit.io/manual/stream-processing/introduction): Perform data selection and transformation using simple SQL queries\n  - Create new streams of data using query results\n  - Aggregation Windows\n  - Data analysis and prediction: Timeseries forecasting\n- Portable: runs on Linux, MacOS, Windows and BSD systems\n\n## Fluent Bit in Production\n\nFluent Bit is a widely adopted solution in production environments. As of 2024, Fluent Bit has surpassed 15 billion downloads and continues to be deployed over 10 million times daily. Below is a preview of some of the organizations that rely heavily on Fluent Bit in their production systems:\n\n> If your company uses Fluent Bit and is not listed, feel free to open a GitHub issue and we will add the logo.\n\n![users](documentation/fluentbit_users.png)\n\n## [Documentation](https://docs.fluentbit.io)\n\nOur official project documentation for [installation](https://docs.fluentbit.io/manual/installation), [configuration](https://docs.fluentbit.io/manual/administration/configuring-fluent-bit), deployment and development topics is located here:\n\n- [https://docs.fluentbit.io](https://fluentbit.io)\n\n### Quick Start\n\n#### Build from Scratch\n\nIf you aim to build Fluent Bit from sources, you can go ahead and start with the following commands.\n\n```bash\ncd build\ncmake ..\nmake\nbin/fluent-bit -i cpu -o stdout -f 1\n```\n\nIf you are interested into more details, please refer to the [Build & Install](https://docs.fluentbit.io/manual/installation/sources/build-and-install) section.\n\n#### Requirements\n\n- CMake >= 3.0\n- Flex\n- Bison\n- YAML library/headers\n- OpenSSL library/headers\n\n#### Linux Packages\n\nWe provide packages for most common Linux distributions:\n\n- [Debian](https://docs.fluentbit.io/manual/installation/linux/debian)\n- [Raspbian](https://docs.fluentbit.io/manual/installation/linux/raspbian-raspberry-pi)\n- [Ubuntu](https://docs.fluentbit.io/manual/installation/linux/ubuntu)\n- [CentOS](https://docs.fluentbit.io/manual/installation/linux/redhat-centos)\n\n#### Linux / Docker Container Images\n\nOur Linux containers images are the most common deployment model, thousands of\nnew installation happen every day, learn more about the available images and\ntags [here](https://docs.fluentbit.io/manual/installation/docker).\n\n#### Windows Packages\n\nFluent Bit is fully supported on Windows environments, get started with [these instructions](https://docs.fluentbit.io/manual/installation/windows).\n\n#### Running on s390x\n\nFluent Bit runs on Linux on IBM Z(s390x), but the WASM filter plugin is not. For the LUA filter plugin, it runs when `libluajit` is installed on the system and fluent bit is built with `FLB_LUAJIT` and `FLB_PREFER_SYSTEM_LIB_LUAJIT` on.\n\n### Plugins: Inputs, Filters and Outputs\n\n[Fluent Bit](http://fluentbit.io) is based in a pluggable architecture where different plugins plays a major role in the data pipeline:\n\n#### Input Plugins\n\n| name | title | description |\n| :--- | :--- | :--- |\n| [collectd](https://docs.fluentbit.io/manual/pipeline/inputs/collectd) | Collectd | Listen for UDP packets from Collectd. |\n| [cpu](https://docs.fluentbit.io/manual/pipeline/inputs/cpu-metrics) | CPU Usage | measure total CPU usage of the system. |\n| [disk](https://docs.fluentbit.io/manual/pipeline/inputs/disk-io-metrics) | Disk Usage | measure Disk I/Os. |\n| [dummy](https://docs.fluentbit.io/manual/pipeline/inputs/dummy) | Dummy | generate dummy event. |\n| [exec](https://docs.fluentbit.io/manual/pipeline/inputs/exec) | Exec | executes external program and collects event logs. |\n| [forward](https://docs.fluentbit.io/manual/pipeline/inputs/forward) | Forward | Fluentd forward protocol. |\n| [head](https://docs.fluentbit.io/manual/pipeline/inputs/head) | Head | read first part of files. |\n| [health](https://docs.fluentbit.io/manual/pipeline/inputs/health) | Health | Check health of TCP services. |\n| [kmsg](https://docs.fluentbit.io/manual/pipeline/inputs/kernel-logs) | Kernel Log Buffer | read the Linux Kernel log buffer messages. |\n| [mem](https://docs.fluentbit.io/manual/pipeline/inputs/memory-metrics) | Memory Usage | measure the total amount of memory used on the system. |\n| [mqtt](https://docs.fluentbit.io/manual/pipeline/inputs/mqtt) | MQTT | start a MQTT server and receive publish messages. |\n| [netif](https://docs.fluentbit.io/manual/pipeline/inputs/network-io-metrics) | Network Traffic | measure network traffic. |\n| [proc](https://docs.fluentbit.io/manual/pipeline/inputs/process) | Process | Check health of Process. |\n| [random](https://docs.fluentbit.io/manual/pipeline/inputs/random) | Random | Generate Random samples. |\n| [serial](https://docs.fluentbit.io/manual/pipeline/inputs/serial-interface) | Serial Interface | read data information from the serial interface. |\n| [stdin](https://docs.fluentbit.io/manual/pipeline/inputs/standard-input) | Standard Input | read data from the standard input. |\n| [syslog](https://docs.fluentbit.io/manual/pipeline/inputs/syslog) | Syslog | read syslog messages from a Unix socket. |\n| [systemd](https://docs.fluentbit.io/manual/pipeline/inputs/systemd) | Systemd | read logs from Systemd/Journald. |\n| [tail](https://docs.fluentbit.io/manual/pipeline/inputs/tail) | Tail | Tail log files. |\n| [tcp](https://docs.fluentbit.io/manual/pipeline/inputs/tcp) | TCP | Listen for JSON messages over TCP. |\n| [thermal](https://docs.fluentbit.io/manual/pipeline/inputs/thermal) | Thermal | measure system temperature(s). |\n\n#### Filter Plugins\n\n| name | title | description |\n| :--- | :--- | :--- |\n| [aws](https://docs.fluentbit.io/manual/pipeline/filters/aws-metadata) | AWS Metadata | Enrich logs with AWS Metadata. |\n| [expect](https://docs.fluentbit.io/manual/pipeline/filters/expect) | Expect | Validate records match certain criteria in structure. |\n| [grep](https://docs.fluentbit.io/manual/pipeline/filters/grep) | Grep | Match or exclude specific records by patterns. |\n| [kubernetes](https://docs.fluentbit.io/manual/pipeline/filters/kubernetes) | Kubernetes | Enrich logs with Kubernetes Metadata. |\n| [lua](https://docs.fluentbit.io/manual/pipeline/filters/lua) | Lua | Filter records using Lua Scripts. |\n| [parser](https://docs.fluentbit.io/manual/pipeline/filters/parser) | Parser | Parse record. |\n| [record\\_modifier](https://docs.fluentbit.io/manual/pipeline/filters/record-modifier) | Record Modifier | Modify record. |\n| [rewrite\\_tag](https://docs.fluentbit.io/manual/pipeline/filters/rewrite-tag) | Rewrite Tag | Re-emit records under new tag. |\n| [stdout](https://docs.fluentbit.io/manual/pipeline/filters/standard-output) | Stdout | Print records to the standard output interface. |\n| [throttle](https://docs.fluentbit.io/manual/pipeline/filters/throttle) | Throttle | Apply rate limit to event flow. |\n| [nest](https://docs.fluentbit.io/manual/pipeline/filters/nest) | Nest | Nest records under a specified key |\n| [modify](https://docs.fluentbit.io/manual/pipeline/filters/modify) | Modify | Modifications to record. |\n\n#### Output Plugins\n\n| name | title | description |\n| :--- | :--- | :--- |\n| [azure](https://docs.fluentbit.io/manual/pipeline/outputs/azure) | Azure Log Analytics | Ingest records into Azure Log Analytics |\n| [bigquery](https://docs.fluentbit.io/manual/pipeline/outputs/bigquery) | BigQuery | Ingest records into Google BigQuery |\n| [counter](https://docs.fluentbit.io/manual/pipeline/outputs/counter) | Count Records | Simple records counter. |\n| [datadog](https://docs.fluentbit.io/manual/pipeline/outputs/datadog) | Datadog | Ingest logs into Datadog. |\n| [es](https://docs.fluentbit.io/manual/pipeline/outputs/elasticsearch) | Elasticsearch | flush records to a Elasticsearch server. |\n| [file](https://docs.fluentbit.io/manual/pipeline/outputs/file) | File | Flush records to a file. |\n| [flowcounter](https://docs.fluentbit.io/manual/pipeline/outputs/flowcounter) | FlowCounter | Count records. |\n| [forward](https://docs.fluentbit.io/manual/pipeline/outputs/forward) | Forward | Fluentd forward protocol. |\n| [gelf](https://docs.fluentbit.io/manual/pipeline/outputs/gelf) | GELF | Flush records to Graylog |\n| [http](https://docs.fluentbit.io/manual/pipeline/outputs/http) | HTTP | Flush records to an HTTP end point. |\n| [influxdb](https://docs.fluentbit.io/manual/pipeline/outputs/influxdb) | InfluxDB | Flush records to InfluxDB time series database. |\n| [kafka](https://docs.fluentbit.io/manual/pipeline/outputs/kafka) | Apache Kafka | Flush records to Apache Kafka |\n| [kafka-rest](https://docs.fluentbit.io/manual/pipeline/outputs/kafka-rest-proxy) | Kafka REST Proxy | Flush records to a Kafka REST Proxy server. |\n| [loki](https://docs.fluentbit.io/manual/pipeline/outputs/loki) | Loki | Flush records to Loki server. |\n| [nats](https://docs.fluentbit.io/manual/pipeline/outputs/nats) | NATS | Flush records to a NATS server. |\n| [null](https://docs.fluentbit.io/manual/pipeline/outputs/null) | NULL | Throw away events. |\n| [s3](https://docs.fluentbit.io/manual/pipeline/outputs/s3) | S3 | Flush records to s3 |\n| [stackdriver](https://docs.fluentbit.io/manual/pipeline/outputs/stackdriver) | Google Stackdriver Logging | Flush records to Google Stackdriver Logging service. |\n| [stdout](https://docs.fluentbit.io/manual/pipeline/outputs/standard-output) | Standard Output | Flush records to the standard output. |\n| [splunk](https://docs.fluentbit.io/manual/pipeline/outputs/splunk) | Splunk | Flush records to a Splunk Enterprise service |\n| [tcp](https://docs.fluentbit.io/manual/pipeline/outputs/tcp-and-tls) | TCP & TLS | Flush records to a TCP server. |\n| [td](https://docs.fluentbit.io/manual/pipeline/outputs/treasure-data) | [Treasure Data](http://www.treasuredata.com) | Flush records to the [Treasure Data](http://www.treasuredata.com) cloud service for analytics. |\n\n## Contributing\n\n[Fluent Bit](https://fluentbit.io) is an open project, several individuals and companies contribute in different forms like coding, documenting, testing, spreading the word at events within others. If you want to learn more about contributing opportunities please reach out to us through our [Community Channels](https://fluentbit.io/community/).\n\nIf you are interested in contributing to Fluent bit with bug fixes, new features or coding in general, please refer to the code [CONTRIBUTING](CONTRIBUTING.md) guidelines. You can also refer the Beginners Guide to contributing to Fluent Bit [here.](DEVELOPER_GUIDE.md)\n\n## Community & Contact\n\nFeel free to join us on our Slack channel, Mailing List or IRC:\n\n- [Slack](http://slack.fluentd.org) (#fluent-bit channel)\n- [Twitter](http://twitter.com/fluentbit)\n\n## License\n\nThis program is under the terms of the [Apache License v2.0](http://www.apache.org/licenses/LICENSE-2.0).\n\n## Authors\n\n[Fluent Bit](http://fluentbit.io) is sponsored and maintained by several companies in the Cloud Native community, including all the major cloud providers.\n\nYou can see a list of contributors [here](https://github.com/fluent/fluent-bit/graphs/contributors).\n\n"
}