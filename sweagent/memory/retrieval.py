import json
from math import e
from typing import List, Dict, Any, Optional
from collections import defaultdict
from sweagent.agent.repo_analyzer import GitHubRepositoryAnalyzer
from sweagent.memory.LongTermMemoryDB import LongTermMemoryDB, MilvusConfig
from sweagent.memory.query_generator import QueryGenerator
from sweagent.utils.log import get_logger
from pymilvus.model.dense import SentenceTransformerEmbeddingFunction


class Retriever:
    """
    è´Ÿè´£ä»å‘é‡æ•°æ®åº“ä¸­æ£€ç´¢çŸ¥è¯†ï¼Œå¹¶ä½¿ç”¨RRFèšåˆç»“æœã€‚
    """

    def __init__(self, memory: LongTermMemoryDB):
        """
        åˆå§‹åŒ–Retrieverã€‚

        Args:
            vector_db: ä¸€ä¸ªå‘é‡æ•°æ®åº“çš„å®ä¾‹ï¼Œéœ€è¦æœ‰ `search(query, top_k)` æ–¹æ³•ã€‚
        """
        self.db = memory
        self.logger = get_logger("Retriever", emoji="ğŸ§ ")

    def _reciprocal_rank_fusion(self, search_results_list: List[List[Dict]], k: int = 60) -> List[Dict]:
        """
        å¯¹å¤šç»„æœç´¢ç»“æœåº”ç”¨Reciprocal Rank Fusion (RRF)

        Args:
            search_results_list: ä¸€ä¸ªåˆ—è¡¨ï¼Œå…¶ä¸­æ¯ä¸ªå…ƒç´ éƒ½æ˜¯ä¸€ä¸ªæŸ¥è¯¢è¿”å›çš„ç»“æœåˆ—è¡¨ã€‚
            k (int): RRFç®—æ³•ä¸­çš„ä¸€ä¸ªå¸¸é‡ï¼Œç”¨äºå¹³è¡¡æ’åçš„å½±å“ã€‚

        Returns:
            ä¸€ä¸ªæ ¹æ®RRFåˆ†æ•°é‡æ–°æ’åºçš„ã€å»é‡çš„æ–‡æ¡£åˆ—è¡¨ã€‚
        """
        fused_scores = defaultdict(float)

        self.logger.info(f"Applying RRF to {len(search_results_list)} sets of search results.")

        # éå†æ¯ä¸ªæŸ¥è¯¢çš„ç»“æœåˆ—è¡¨
        for search_results in search_results_list:
            # éå†è¯¥åˆ—è¡¨ä¸­çš„æ¯ä¸ªæ–‡æ¡£
            for rank, result in enumerate(search_results):
                doc_id = result["id"]
                # RRFæ ¸å¿ƒå…¬å¼ï¼šscore = 1 / (k + rank)
                # æˆ‘ä»¬ä½¿ç”¨ rank+1 æ˜¯å› ä¸º rank ä»0å¼€å§‹
                rrf_score = 1.0 / (k + rank + 1)
                fused_scores[doc_id] += rrf_score

        # æ ¹æ®èåˆåçš„åˆ†æ•°å¯¹æ–‡æ¡£IDè¿›è¡Œæ’åº
        reranked_ids = sorted(fused_scores.keys(), key=lambda id: fused_scores[id], reverse=True)

        # åˆ›å»ºä¸€ä¸ªå»é‡çš„ã€é‡æ’åºçš„æ–‡æ¡£åˆ—è¡¨
        # é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ªä»IDåˆ°å®Œæ•´æ–‡æ¡£çš„æ˜ å°„
        all_docs_map = {}
        for search_results in search_results_list:
            for result in search_results:
                if result["id"] not in all_docs_map:
                    all_docs_map[result["id"]] = {
                        "problem": result["problem"],
                        "solution": result["solution"],
                        "action": result["action"],
                    }

        final_results = [all_docs_map[doc_id] for doc_id in reranked_ids]

        self.logger.info(f"RRF resulted in {len(final_results)} unique, reranked items.")
        return final_results

    def retrieve_and_aggregate(self, queries: List[str], top_k_per_query: int = 3) -> List[Dict]:
        """
        æ‰§è¡Œå¤šæŸ¥è¯¢æ£€ç´¢ã€RRFèšåˆå’Œæœ€åçš„ç»“æœæ ¼å¼åŒ–ã€‚

        Args:
            queries: ä»ç¬¬äºŒé˜¶æ®µç”Ÿæˆçš„å‡è®¾æ€§é—®é¢˜åˆ—è¡¨ã€‚
            top_k_per_query: æ¯ä¸ªæŸ¥è¯¢è¦æ£€ç´¢çš„æ–‡æ¡£æ•°é‡ã€‚

        Returns:
            ä¸€ä¸ªæœ‰åºçš„ã€èšåˆåçš„çŸ¥è¯†æ¡ç›®åˆ—è¡¨ï¼Œæ¯ä¸ªæ¡ç›®åŒ…å«Solutionå’ŒActionã€‚
        """
        if not queries:
            self.logger.warning("No queries provided for retrieval.")
            return []

        # 1. å¹¶è¡Œæˆ–ä¸²è¡Œåœ°ä¸ºæ¯ä¸ªæŸ¥è¯¢æ‰§è¡Œæœç´¢
        # åœ¨å®é™…åº”ç”¨ä¸­ï¼Œå¦‚æœæ•°æ®åº“æ”¯æŒï¼Œè¿™é‡Œå¯ä»¥æ˜¯å¹¶è¡Œçš„ã€‚
        all_search_results = []
        self.logger.info(f"Performing search for {len(queries)} queries...")
        for query in queries:
            results = self.db.query_similar(query, topk=top_k_per_query)
            if results:
                all_search_results.append(results)

        if not all_search_results:
            self.logger.warning("No relevant documents found for any of the queries.")
            return []

        # 2. ä½¿ç”¨RRFèšåˆç»“æœ
        final_results = self._reciprocal_rank_fusion(all_search_results)

        return final_results


if __name__ == "__main__":
    with open("data/stage3_2_new_simplified.jsonl", "r") as f:
        data = [json.loads(line) for line in f]

    query_generator = QueryGenerator()
    embedding_model = SentenceTransformerEmbeddingFunction(
        model_name="Qwen/Qwen3-Embedding-8B", device="cuda:7", batch_size=1
    )
    milvus_config = MilvusConfig(collection_name="Stage_3_2")
    memory = LongTermMemoryDB(config=milvus_config, embedding_model=embedding_model)
    retriever = Retriever(memory)

    # 2. æ‰§è¡Œæ£€ç´¢å’Œèšåˆ
    for instance in data:
        analyzer = GitHubRepositoryAnalyzer(
            github_url=None,
            org=instance["org"],
            repo=instance["repo"],
            number=int(instance["number"]),
            commit=instance["commit"],
        )
        metadata = analyzer.create_metadata_file()
        query_generator = QueryGenerator()
        queries, profile = query_generator.generate_queries_from_guidelines(metadata)
        knowledge = retriever.retrieve_and_aggregate(queries)
        project_profile = profile.model_dump()
        instance["knowledge"] = knowledge
        instance["profile"] = project_profile
        instance["queries"] = queries
        retriever.logger.info(instance)
        break
